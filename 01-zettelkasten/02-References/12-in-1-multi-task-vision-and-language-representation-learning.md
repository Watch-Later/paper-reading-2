---
title: 12-in-1 - Multi-Task Vision and Language Representation Learning
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# 12-in-1 - Multi-Task Vision and Language Representation Learning

## References

- Multi-Task Learning of Hierarchical Vision-Language Representation
- [ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks](./vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks.md)
- [Unified Vision-Language Pre-Training for Image Captioning and VQA](./unified-vision-language-pre-training-for-image-captioning-and-vqa.md)
- [Visual7W - Grounded Question Answering in Images](./visual7w-grounded-question-answering-in-images.md)
- [VisualBERT - A Simple and Performant Baseline for Vision and Language](./visualbert-a-simple-and-performant-baseline-for-vision-and-language.md)
- [LXMERT - Learning Cross-Modality Encoder Representations from Transformers](./lxmert-learning-cross-modality-encoder-representations-from-transformers.md)
- [VL-BERT - Pre-training of Generic Visual-Linguistic Representations](./vl-bert-pre-training-of-generic-visual-linguistic-representations.md)
- [Multi-Task Deep Neural Networks for Natural Language Understanding](./multi-task-deep-neural-networks-for-natural-language-understanding.md)
- OmniNet - A unified architecture for multi-modal multi-task learning
- UberNet - Training a Universal Convolutional Neural Network for Low-, Mid-, and High-Level Vision Using Diverse Datasets and Limited Memory
- Many Task Learning With Task Routing
- Which Tasks Should Be Learned Together in Multi-task Learning?
- [Unicoder-VL - A Universal Encoder for Vision and Language by Cross-modal Pre-training](./unicoder-vl-a-universal-encoder-for-vision-and-language-by-cross-modal-pre-training.md)
- Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval
- [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](./exploring-the-limits-of-transfer-learning-with-a-unified-text-to-text-transformer.md)
- [Making the V in VQA Matter - Elevating the Role of Image Understanding in Visual Question Answering](./making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering.md)
- Cross-Stitch Networks for Multi-task Learning
- [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](./visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations.md)
- [MAttNet - Modular Attention Network for Referring Expression Comprehension](./mattnet-modular-attention-network-for-referring-expression-comprehension.md)
- [BAM! Born-Again Multi-Task Networks for Natural Language Understanding](./bam-born-again-multi-task-networks-for-natural-language-understanding.md)
- [UNITER - Learning UNiversal Image-TExt Representations](./uniter-learning-universal-image-text-representations.md)
- Visual Entailment Task for Visually-Grounded Language Learning
- [Attention is All you Need](./attention-is-all-you-need.md)
- [A unified architecture for natural language processing - deep neural networks with multitask learning](./a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning.md)
- [Visual Dialog](./visual-dialog.md)
- [Hierarchical Question-Image Co-Attention for Visual Question Answering](./hierarchical-question-image-co-attention-for-visual-question-answering.md)
- [Fusion of Detected Objects in Text for Visual Question Answering](./fusion-of-detected-objects-in-text-for-visual-question-answering.md)
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- [From Recognition to Cognition - Visual Commonsense Reasoning](./from-recognition-to-cognition-visual-commonsense-reasoning.md)
- [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](./bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering.md)
- Stochastic Filter Groups for Multi-Task CNNs - Learning Specialist and Generalist Convolution Kernels
- [Stacked Cross Attention for Image-Text Matching](./stacked-cross-attention-for-image-text-matching.md)
- The Dialogue Dodecathlon - Open-Domain Knowledge and Image Grounded Conversational Agents
- [Neural Baby Talk](./neural-baby-talk.md)
- Flickr30k Entities - Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models
- GuessWhat?! Visual Object Discovery through Multi-modal Dialogue
- GQA - a new dataset for compositional question answering over real-world images
- [SpanBERT - Improving Pre-training by Representing and Predicting Spans](./spanbert-improving-pre-training-by-representing-and-predicting-spans.md)
- Multitask Learning
- [Modeling Relationships in Referential Expressions with Compositional Modular Networks](./modeling-relationships-in-referential-expressions-with-compositional-modular-networks.md)
- [GQA - A New Dataset for Real-World Visual Reasoning and Compositional Question Answering](./gqa-a-new-dataset-for-real-world-visual-reasoning-and-compositional-question-answering.md)
- [Generation and Comprehension of Unambiguous Object Descriptions](./generation-and-comprehension-of-unambiguous-object-descriptions.md)
- [An Overview of Multi-task Learning](./an-overview-of-multi-task-learning.md)
- [Cross-lingual Language Model Pretraining](./cross-lingual-language-model-pretraining.md)
- [Embodied Question Answering](./embodied-question-answering.md)
- [Aggregated Residual Transformations for Deep Neural Networks](./aggregated-residual-transformations-for-deep-neural-networks.md)
- [An Overview of Multi-Task Learning in Deep Neural Networks](./an-overview-of-multi-task-learning-in-deep-neural-networks.md)
- [Vision-and-Language Navigation - Interpreting Visually-Grounded Navigation Instructions in Real Environments](./vision-and-language-navigation-interpreting-visually-grounded-navigation-instructions-in-real-environments.md)
- Distral - Robust multitask reinforcement learning
- [XLNet - Generalized Autoregressive Pretraining for Language Understanding](./xlnet-generalized-autoregressive-pretraining-for-language-understanding.md)
- [A Corpus for Reasoning about Natural Language Grounded in Photographs](./a-corpus-for-reasoning-about-natural-language-grounded-in-photographs.md)
- Facial Landmark Detection by Deep Multi-task Learning
- [RoBERTa - A Robustly Optimized BERT Pretraining Approach](./roberta-a-robustly-optimized-bert-pretraining-approach.md)
- Reinforcement Learning with Unsupervised Auxiliary Tasks
- [Curriculum learning](./curriculum-learning.md)
- Robust Visual Tracking via Structured Multi-Task Sparse Learning
- [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](./faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.md)
- [Actor-Mimic - Deep Multitask and Transfer Reinforcement Learning](./actor-mimic-deep-multitask-and-transfer-reinforcement-learning.md)
- [Conceptual Captions - A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning](./conceptual-captions-a-cleaned-hypernymed-image-alt-text-dataset-for-automatic-image-captioning.md)
- [Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network](./feature-rich-part-of-speech-tagging-with-a-cyclic-dependency-network.md)
- ReferItGame - Referring to Objects in Photographs of Natural Scenes
- Fixing Weight Decay Regularization in Adam
- Im2Text - Describing Images Using 1 Million Captioned Photographs
- [Decoupled Weight Decay Regularization](./decoupled-weight-decay-regularization.md)
- [Microsoft COCO Captions - Data Collection and Evaluation Server](./microsoft-coco-captions-data-collection-and-evaluation-server.md)
- [The Natural Language Decathlon - Multitask Learning as Question Answering](./the-natural-language-decathlon-multitask-learning-as-question-answering.md)
