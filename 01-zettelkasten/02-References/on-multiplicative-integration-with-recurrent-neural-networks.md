---
title: On Multiplicative Integration with Recurrent Neural Networks
authors:
- Yuhuai Wu
- Saizheng Zhang
- Y. Zhang
- Yoshua Bengio
- R. Salakhutdinov
fieldsOfStudy:
- Computer Science
meta_key: on-multiplicative-integration-with-recurrent-neural-networks
numCitedBy: 129
pdf_relpath: null
ref_count: 36
status: todo
tags:
- gen-from-ref
- paper
venue: NIPS
year: 2016
---

# On Multiplicative Integration with Recurrent Neural Networks

## References

- [An Empirical Exploration of Recurrent Network Architectures](./an-empirical-exploration-of-recurrent-network-architectures.md)
- [Generating Text with Recurrent Neural Networks](./generating-text-with-recurrent-neural-networks.md)
- Architectural Complexity Measures of Recurrent Neural Networks
- Gated Feedback Recurrent Neural Networks
- [Recurrent Batch Normalization](./recurrent-batch-normalization.md)
- Regularizing RNNs by Stabilizing Activations
- Regularization and nonlinearities for neural language models - when are they needed?
- Semi-Supervised Learning with Ladder Network
- [Semi-supervised Learning with Ladder Networks](./semi-supervised-learning-with-ladder-networks.md)
- Deconstructing the Ladder Network Architecture
- SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS
- [Long Short-Term Memory](./long-short-term-memory.md)
- [Grid Long Short-Term Memory](./grid-long-short-term-memory.md)
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](./learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation.md)
- Refining hidden Markov models with recurrent neural networks
- [Skip-Thought Vectors](./skip-thought-vectors.md)
- Second-order recurrent neural networks for grammatical inference
- [Generating Sequences With Recurrent Neural Networks](./generating-sequences-with-recurrent-neural-networks.md)
- [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](./batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
- [Connectionist temporal classification - labelling unsegmented sequence data with recurrent neural networks](./connectionist-temporal-classification-labelling-unsegmented-sequence-data-with-recurrent-neural-networks.md)
- Embedding Entities and Relations for Learning and Inference in Knowledge Bases
- First-order versus second-order single-layer recurrent neural networks
- [Towards End-To-End Speech Recognition with Recurrent Neural Networks](./towards-end-to-end-speech-recognition-with-recurrent-neural-networks.md)
- [End-to-end attention-based large vocabulary speech recognition](./end-to-end-attention-based-large-vocabulary-speech-recognition.md)
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- EESEN - End-to-end speech recognition using deep RNN models and WFST-based decoding
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- First-Pass Large Vocabulary Continuous Speech Recognition using Bi-Directional Recurrent DNNs
- [Teaching Machines to Read and Comprehend](./teaching-machines-to-read-and-comprehend.md)
- [Theano - A Python framework for fast computation of mathematical expressions](./theano-a-python-framework-for-fast-computation-of-mathematical-expressions.md)
- Weighted finite-state transducers in speech recognition
- Building a Large Annotated Corpus of English - The Penn Treebank
- An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology
