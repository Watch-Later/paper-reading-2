---
title: ERNIE-ViL - Knowledge Enhanced Vision-Language Representations Through Scene Graph
authors:
- Fei Yu
- Jiji Tang
- Weichong Yin
- Yu Sun
- Hao Tian
- Hua Wu
- Haifeng Wang
fieldsOfStudy:
- Computer Science
meta_key: ernie-vil-knowledge-enhanced-vision-language-representations-through-scene-graph
numCitedBy: 125
pdf_relpath: null
ref_count: 45
status: todo
tags:
- gen-from-ref
- paper
venue: AAAI
year: 2021
---

# ERNIE-ViL - Knowledge Enhanced Vision-Language Representations Through Scene Graph

## References

- An Empirical Study on Leveraging Scene Graphs for Visual Question Answering
- [ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks](./vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks.md)
- [Attention is All you Need](./attention-is-all-you-need.md)
- [SPICE - Semantic Propositional Image Caption Evaluation](./spice-semantic-propositional-image-caption-evaluation.md)
- [Conceptual Captions - A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning](./conceptual-captions-a-cleaned-hypernymed-image-alt-text-dataset-for-automatic-image-captioning.md)
- [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](./visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations.md)
- Im2Text - Describing Images Using 1 Million Captioned Photographs
- [Large-Scale Adversarial Training for Vision-and-Language Representation Learning](./large-scale-adversarial-training-for-vision-and-language-representation-learning.md)
- [Oscar - Object-Semantics Aligned Pre-training for Vision-Language Tasks](./oscar-object-semantics-aligned-pre-training-for-vision-language-tasks.md)
- [Pixel-BERT - Aligning Image Pixels with Text by Deep Multi-Modal Transformers](./pixel-bert-aligning-image-pixels-with-text-by-deep-multi-modal-transformers.md)
- Circle Loss - A Unified Perspective of Pair Similarity Optimization
- [ImageBERT - Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data](./imagebert-cross-modal-pre-training-with-large-scale-weak-supervised-image-text-data.md)
- [12-in-1 - Multi-Task Vision and Language Representation Learning](./12-in-1-multi-task-vision-and-language-representation-learning.md)
- [UNITER - Learning UNiversal Image-TExt Representations](./uniter-learning-universal-image-text-representations.md)
- [Unified Vision-Language Pre-Training for Image Captioning and VQA](./unified-vision-language-pre-training-for-image-captioning-and-vqa.md)
- [VL-BERT - Pre-training of Generic Visual-Linguistic Representations](./vl-bert-pre-training-of-generic-visual-linguistic-representations.md)
- [LXMERT - Learning Cross-Modality Encoder Representations from Transformers](./lxmert-learning-cross-modality-encoder-representations-from-transformers.md)
- [Unicoder-VL - A Universal Encoder for Vision and Language by Cross-modal Pre-training](./unicoder-vl-a-universal-encoder-for-vision-and-language-by-cross-modal-pre-training.md)
- [VisualBERT - A Simple and Performant Baseline for Vision and Language](./visualbert-a-simple-and-performant-baseline-for-vision-and-language.md)
- ERNIE 2.0 - A Continual Pre-training Framework for Language Understanding
- Unified Visual-Semantic Embeddings - Bridging Vision and Language With Structured Meaning Representations
- ERNIE - Enhanced Representation through Knowledge Integration
- [VideoBERT - A Joint Model for Video and Language Representation Learning](./videobert-a-joint-model-for-video-and-language-representation-learning.md)
- [Auto-Encoding Scene Graphs for Image Captioning](./auto-encoding-scene-graphs-for-image-captioning.md)
- [From Recognition to Cognition - Visual Commonsense Reasoning](./from-recognition-to-cognition-visual-commonsense-reasoning.md)
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- [Improving Language Understanding by Generative Pre-Training](./improving-language-understanding-by-generative-pre-training.md)
- [Image Generation from Scene Graphs](./image-generation-from-scene-graphs.md)
- [Stacked Cross Attention for Image-Text Matching](./stacked-cross-attention-for-image-text-matching.md)
- Scene Graph Parsing as Dependency Parsing
- [MAttNet - Modular Attention Network for Referring Expression Comprehension](./mattnet-modular-attention-network-for-referring-expression-comprehension.md)
- [Neural Motifs - Scene Graph Parsing with Global Context](./neural-motifs-scene-graph-parsing-with-global-context.md)
- [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](./bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering.md)
- [Scene Graph Generation by Iterative Message Passing](./scene-graph-generation-by-iterative-message-passing.md)
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- Generating Semantically Precise Scene Graphs from Textual Descriptions for Improved Image Retrieval
- Image retrieval using scene graphs
- [From image descriptions to visual denotations - New similarity metrics for semantic inference over event descriptions](./from-image-descriptions-to-visual-denotations-new-similarity-metrics-for-semantic-inference-over-event-descriptions.md)
- [VQA - Visual Question Answering](./vqa-visual-question-answering.md)
- [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](./faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.md)
- ReferItGame - Referring to Objects in Photographs of Natural Scenes
- [Microsoft COCO - Common Objects in Context](./microsoft-coco-common-objects-in-context.md)
