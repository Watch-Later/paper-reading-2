---
title: Large-Scale Adversarial Training for Vision-and-Language Representation Learning
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# Large-Scale Adversarial Training for Vision-and-Language Representation Learning

## References

- Adversarial Training for Large Neural Language Models
- FreeLB - Enhanced Adversarial Training for Language Understanding
- Behind the Scene - Revealing the Secrets of Pre-trained Vision-and-Language Models
- Improving Neural Language Modeling via Adversarial Training
- Overcoming Language Priors in Visual Question Answering with Adversarial Regularization
- [Adversarial Training Methods for Semi-Supervised Text Classification](./adversarial-training-methods-for-semi-supervised-text-classification.md)
- [UNITER - Learning UNiversal Image-TExt Representations](./uniter-learning-universal-image-text-representations.md)
- Using Pre-Training Can Improve Model Robustness and Uncertainty
- You Only Propagate Once - Accelerating Adversarial Training via Maximal Principle
- Virtual Adversarial Training - A Regularization Method for Supervised and Semi-Supervised Learning
- Attacking Visual Language Grounding with Adversarial Examples - A Case Study on Neural Image Captioning
- [Unicoder-VL - A Universal Encoder for Vision and Language by Cross-modal Pre-training](./unicoder-vl-a-universal-encoder-for-vision-and-language-by-cross-modal-pre-training.md)
- Adversarial Robustness - From Self-Supervised Pre-Training to Fine-Tuning
- [ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks](./vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks.md)
- [Unified Vision-Language Pre-Training for Image Captioning and VQA](./unified-vision-language-pre-training-for-image-captioning-and-vqa.md)
- Adversarial Training for Free!
- [VideoBERT - A Joint Model for Video and Language Representation Learning](./videobert-a-joint-model-for-video-and-language-representation-learning.md)
- Adversarial Examples Improve Image Recognition
- Boosting Adversarial Training with Hypersphere Embedding
- [LXMERT - Learning Cross-Modality Encoder Representations from Transformers](./lxmert-learning-cross-modality-encoder-representations-from-transformers.md)
- Large-scale Pretraining for Visual Dialog - A Simple State-of-the-Art Baseline
- Metric Learning for Adversarial Robustness
- Improving the Robustness of Deep Neural Networks via Adversarial Training with Triplet Loss
- [12-in-1 - Multi-Task Vision and Language Representation Learning](./12-in-1-multi-task-vision-and-language-representation-learning.md)
- [Feature Denoising for Improving Adversarial Robustness](./feature-denoising-for-improving-adversarial-robustness.md)
- [Oscar - Object-Semantics Aligned Pre-training for Vision-Language Tasks](./oscar-object-semantics-aligned-pre-training-for-vision-language-tasks.md)
- Fast is better than free - Revisiting adversarial training
- Are Labels Required for Improving Adversarial Robustness?
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- Exact Adversarial Attack to Image Captioning via Structured Output Learning With Latent Variables
- [Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering](./multi-modal-factorized-bilinear-pooling-with-co-attention-learning-for-visual-question-answering.md)
- Ensemble Adversarial Training - Attacks and Defenses
- Towards Learning a Generic Agent for Vision-and-Language Navigation via Pre-Training
- VD-BERT - A Unified Vision and Dialog Transformer with BERT
- [Explaining and Harnessing Adversarial Examples](./explaining-and-harnessing-adversarial-examples.md)
- [From Recognition to Cognition - Visual Commonsense Reasoning](./from-recognition-to-cognition-visual-commonsense-reasoning.md)
- Unlabeled Data Improves Adversarial Robustness
- [VisualBERT - A Simple and Performant Baseline for Vision and Language](./visualbert-a-simple-and-performant-baseline-for-vision-and-language.md)
- [Making the V in VQA Matter - Elevating the Role of Image Understanding in Visual Question Answering](./making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering.md)
- Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training
- [VL-BERT - Pre-training of Generic Visual-Linguistic Representations](./vl-bert-pre-training-of-generic-visual-linguistic-representations.md)
- Visual Entailment - A Novel Task for Fine-Grained Image Understanding
- XGPT - Cross-modal Generative Pre-Training for Image Captioning
- Hero - Hierarchical Encoder for Video+Language Omni-representation Pre-training
- Towards Deep Learning Models Resistant to Adversarial Attacks
- [Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding](./multimodal-compact-bilinear-pooling-for-visual-question-answering-and-visual-grounding.md)
- [Deep Modular Co-Attention Networks for Visual Question Answering](./deep-modular-co-attention-networks-for-visual-question-answering.md)
- [Learning Conditioned Graph Structures for Interpretable Visual Question Answering](./learning-conditioned-graph-structures-for-interpretable-visual-question-answering.md)
- [Attention is All you Need](./attention-is-all-you-need.md)
- Unsupervised Data Augmentation for Consistency Training
- [Neural Module Networks](./neural-module-networks.md)
- [Contrastive Bidirectional Transformer for Temporal Representation Learning](./contrastive-bidirectional-transformer-for-temporal-representation-learning.md)
- SMART - Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization
- [Pixel-BERT - Aligning Image Pixels with Text by Deep Multi-Modal Transformers](./pixel-bert-aligning-image-pixels-with-text-by-deep-multi-modal-transformers.md)
- [Hierarchical Question-Image Co-Attention for Visual Question Answering](./hierarchical-question-image-co-attention-for-visual-question-answering.md)
- UniViLM - A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation
- [MUREL - Multimodal Relational Reasoning for Visual Question Answering](./murel-multimodal-relational-reasoning-for-visual-question-answering.md)
- [Fusion of Detected Objects in Text for Visual Question Answering](./fusion-of-detected-objects-in-text-for-visual-question-answering.md)
- Semantically Equivalent Adversarial Rules for Debugging NLP models
- 5分で分かる!? 有名論文ナナメ読み：Jacob Devlin et al. - BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding
- [GQA - A New Dataset for Real-World Visual Reasoning and Compositional Question Answering](./gqa-a-new-dataset-for-real-world-visual-reasoning-and-compositional-question-answering.md)
- [Bilinear Attention Networks](./bilinear-attention-networks.md)
- [Learning to Reason - End-to-End Module Networks for Visual Question Answering](./learning-to-reason-end-to-end-module-networks-for-visual-question-answering.md)
- [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](./visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations.md)
- [Relation-Aware Graph Attention Network for Visual Question Answering](./relation-aware-graph-attention-network-for-visual-question-answering.md)
- [Intriguing properties of neural networks](./intriguing-properties-of-neural-networks.md)
- [Compositional Attention Networks for Machine Reasoning](./compositional-attention-networks-for-machine-reasoning.md)
- Improving Vision-and-Language Navigation with Image-Text Pairs from the Web
- Flickr30k Entities - Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models
- 5分で分かる!? 有名論文ナナメ読み：Jacob Devlin et al. - BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding
- [A simple neural network module for relational reasoning](./a-simple-neural-network-module-for-relational-reasoning.md)
- [Stacked Cross Attention for Image-Text Matching](./stacked-cross-attention-for-image-text-matching.md)
- [Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering](./dynamic-fusion-with-intra-and-inter-modality-attention-flow-for-visual-question-answering.md)
- [Stacked Attention Networks for Image Question Answering](./stacked-attention-networks-for-image-question-answering.md)
- [Conceptual Captions - A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning](./conceptual-captions-a-cleaned-hypernymed-image-alt-text-dataset-for-automatic-image-captioning.md)
- [Modeling Context in Referring Expressions](./modeling-context-in-referring-expressions.md)
- Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog
- Meta Module Network for Compositional Visual Reasoning
- [Microsoft COCO - Common Objects in Context](./microsoft-coco-common-objects-in-context.md)
- 5分で分かる!? 有名論文ナナメ読み：Jacob Devlin et al. - BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding
- Im2Text - Describing Images Using 1 Million Captioned Photographs
- [Inferring and Executing Programs for Visual Reasoning](./inferring-and-executing-programs-for-visual-reasoning.md)
- Obfuscated Gradients Give a False Sense of Security - Circumventing Defenses to Adversarial Examples
- 5分で分かる!? 有名論文ナナメ読み：Jacob Devlin et al. - BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding
- [UNITER - UNiversal Image-TExt Representation Learning](./uniter-universal-image-text-representation-learning.md)
- [Learning Video Representations using Contrastive Bidirectional Transformer](./learning-video-representations-using-contrastive-bidirectional-transformer.md)
- FreeLB - Enhanced Adversarial Training for Natural Language Understanding
- Cycle-Consistency for Robust Visual Question Answering
- VQA - Visual Question Answering
- Show-and-Fool - Crafting Adversarial Examples for Neural Image Captioning
