---
title: Show, Ask, Attend, and Answer - A Strong Baseline For Visual Question Answering
authors:
- V. Kazemi
- A. Elqursh
fieldsOfStudy:
- Computer Science
meta_key: show-ask-attend-and-answer-a-strong-baseline-for-visual-question-answering
numCitedBy: 135
pdf_relpath: null
ref_count: 34
status: todo
tags:
- gen-from-ref
- paper
venue: ArXiv
year: 2017
---

# Show, Ask, Attend, and Answer - A Strong Baseline For Visual Question Answering

## References

- [Making the V in VQA Matter - Elevating the Role of Image Understanding in Visual Question Answering](./making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering.md)
- [VQA - Visual Question Answering](./vqa-visual-question-answering.md)
- [Hierarchical Question-Image Co-Attention for Visual Question Answering](./hierarchical-question-image-co-attention-for-visual-question-answering.md)
- [Ask Me Anything - Free-Form Visual Question Answering Based on Knowledge from External Sources](./ask-me-anything-free-form-visual-question-answering-based-on-knowledge-from-external-sources.md)
- [Show and tell - A neural image caption generator](./show-and-tell-a-neural-image-caption-generator.md)
- [Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding](./multimodal-compact-bilinear-pooling-for-visual-question-answering-and-visual-grounding.md)
- [Dynamic Memory Networks for Visual and Textual Question Answering](./dynamic-memory-networks-for-visual-and-textual-question-answering.md)
- [Stacked Attention Networks for Image Question Answering](./stacked-attention-networks-for-image-question-answering.md)
- Training Recurrent Answering Units with Joint Loss Minimization for VQA
- [Neural Module Networks](./neural-module-networks.md)
- [Show, Attend and Tell - Neural Image Caption Generation with Visual Attention](./show-attend-and-tell-neural-image-caption-generation-with-visual-attention.md)
- [DenseCap - Fully Convolutional Localization Networks for Dense Captioning](./densecap-fully-convolutional-localization-networks-for-dense-captioning.md)
- [Multimodal Residual Learning for Visual QA](./multimodal-residual-learning-for-visual-qa.md)
- [Return of the Devil in the Details - Delving Deep into Convolutional Nets](./return-of-the-devil-in-the-details-delving-deep-into-convolutional-nets.md)
- [Rethinking the Inception Architecture for Computer Vision](./rethinking-the-inception-architecture-for-computer-vision.md)
- [Generation and Comprehension of Unambiguous Object Descriptions](./generation-and-comprehension-of-unambiguous-object-descriptions.md)
- [Dual Attention Networks for Multimodal Reasoning and Matching](./dual-attention-networks-for-multimodal-reasoning-and-matching.md)
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [Microsoft COCO - Common Objects in Context](./microsoft-coco-common-objects-in-context.md)
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](./very-deep-convolutional-networks-for-large-scale-image-recognition.md)
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- [Neural Machine Translation by Jointly Learning to Align and Translate](./neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
- [ImageNet classification with deep convolutional neural networks](./imagenet-classification-with-deep-convolutional-neural-networks.md)
- Convolutional networks and applications in vision
- [Going deeper with convolutions](./going-deeper-with-convolutions.md)
- [Understanding the difficulty of training deep feedforward neural networks](./understanding-the-difficulty-of-training-deep-feedforward-neural-networks.md)
- [Recurrent Models of Visual Attention](./recurrent-models-of-visual-attention.md)
- [Improving neural networks by preventing co-adaptation of feature detectors](./improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors.md)
- [Long Short-Term Memory](./long-short-term-memory.md)
- [Long short-term memory recurrent neural network architectures for large scale acoustic modeling](./long-short-term-memory-recurrent-neural-network-architectures-for-large-scale-acoustic-modeling.md)
- [Rectified Linear Units Improve Restricted Boltzmann Machines](./rectified-linear-units-improve-restricted-boltzmann-machines.md)
