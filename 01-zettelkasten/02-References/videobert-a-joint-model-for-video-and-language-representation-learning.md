---
title: VideoBERT - A Joint Model for Video and Language Representation Learning
authors:
- Chen Sun
- Austin Myers
- Carl Vondrick
- K. Murphy
- C. Schmid
fieldsOfStudy:
- Computer Science
meta_key: videobert-a-joint-model-for-video-and-language-representation-learning
numCitedBy: 569
pdf_relpath: null
ref_count: 40
status: todo
tags:
- gen-from-ref
- paper
venue: 2019 IEEE/CVF International Conference on Computer Vision (ICCV)
year: 2019
---

# VideoBERT - A Joint Model for Video and Language Representation Learning

## References

- [Shuffle and Learn - Unsupervised Learning Using Temporal Order Verification](./shuffle-and-learn-unsupervised-learning-using-temporal-order-verification.md)
- SoundNet - Learning Sound Representations from Unlabeled Video
- Anticipating Visual Representations from Unlabeled Video
- [Generating Videos with Scene Dynamics](./generating-videos-with-scene-dynamics.md)
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- [Deep multi-scale video prediction beyond mean square error](./deep-multi-scale-video-prediction-beyond-mean-square-error.md)
- [Neural Baby Talk](./neural-baby-talk.md)
- Weakly-Supervised Video Object Grounding from Text by Loss Weighting and Object Interaction
- [Attention is All you Need](./attention-is-all-you-need.md)
- Stochastic Variational Video Prediction
- SLAC - A Sparsely Labeled Dataset for Action Classification and Localization
- Visual Dynamics - Probabilistic Future Frame Synthesis via Cross Convolutional Networks
- [End-to-End Dense Video Captioning with Masked Transformer](./end-to-end-dense-video-captioning-with-masked-transformer.md)
- [Revisiting Unreasonable Effectiveness of Data in Deep Learning Era](./revisiting-unreasonable-effectiveness-of-data-in-deep-learning-era.md)
- Unsupervised Learning from Narrated Instruction Videos
- COIN - A Large-Scale Dataset for Comprehensive Instructional Video Analysis
- An Uncertain Future - Forecasting from Static Images Using Variational Autoencoders
- Dense-Captioning Events in Videos
- [Cross-lingual Language Model Pretraining](./cross-lingual-language-model-pretraining.md)
- Towards Automatic Learning of Procedures From Web Instructional Videos
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- Stochastic Video Generation with a Learned Prior
- Moments in Time Dataset - One Million Videos for Event Understanding
- Rethinking Spatiotemporal Feature Learning For Video Understanding
- Stochastic Adversarial Video Prediction
- MoCoGAN - Decomposing Motion and Content for Video Generation
- AVA - A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions
- [CIDEr - Consensus-based image description evaluation](./cider-consensus-based-image-description-evaluation.md)
- [Going deeper with convolutions](./going-deeper-with-convolutions.md)
- [Ambient Sound Provides Supervision for Visual Learning](./ambient-sound-provides-supervision-for-visual-learning.md)
- The Kinetics Human Action Video Dataset
- [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](./google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation.md)
- What's Cookin'? Interpreting Cooking Videos using Text, Speech and Vision
- Baby Talk - Understanding and Generating Image Descriptions
- [BERT has a Mouth, and It Must Speak - BERT as a Markov Random Field Language Model](./bert-has-a-mouth-and-it-must-speak-bert-as-a-markov-random-field-language-model.md)
- [ROUGE - A Package for Automatic Evaluation of Summaries](./rouge-a-package-for-automatic-evaluation-of-summaries.md)
- [Visually Indicated Sounds](./visually-indicated-sounds.md)
