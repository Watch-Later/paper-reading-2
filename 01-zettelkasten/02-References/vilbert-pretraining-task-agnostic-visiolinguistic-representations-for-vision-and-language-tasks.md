---
title: ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks

## References

- [VisualBERT - A Simple and Performant Baseline for Vision and Language](./visualbert-a-simple-and-performant-baseline-for-vision-and-language.md)
- [VL-BERT - Pre-training of Generic Visual-Linguistic Representations](./vl-bert-pre-training-of-generic-visual-linguistic-representations.md)
- [Unified Vision-Language Pre-Training for Image Captioning and VQA](./unified-vision-language-pre-training-for-image-captioning-and-vqa.md)
- [Unicoder-VL - A Universal Encoder for Vision and Language by Cross-modal Pre-training](./unicoder-vl-a-universal-encoder-for-vision-and-language-by-cross-modal-pre-training.md)
- [LXMERT - Learning Cross-Modality Encoder Representations from Transformers](./lxmert-learning-cross-modality-encoder-representations-from-transformers.md)
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- Modulating early visual processing by language
- [MAttNet - Modular Attention Network for Referring Expression Comprehension](./mattnet-modular-attention-network-for-referring-expression-comprehension.md)
- [VideoBERT - A Joint Model for Video and Language Representation Learning](./videobert-a-joint-model-for-video-and-language-representation-learning.md)
- Visual Dialog
- [From Recognition to Cognition - Visual Commonsense Reasoning](./from-recognition-to-cognition-visual-commonsense-reasoning.md)
- FOIL it! Find One mismatch between Image and Language caption
- [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](./visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations.md)
- [Attention is All you Need](./attention-is-all-you-need.md)
- [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](./bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering.md)
- [Vision-and-Language Navigation - Interpreting Visually-Grounded Navigation Instructions in Real Environments](./vision-and-language-navigation-interpreting-visually-grounded-navigation-instructions-in-real-environments.md)
- [Unsupervised Visual Representation Learning by Context Prediction](./unsupervised-visual-representation-learning-by-context-prediction.md)
- Look, Listen and Learn
- [VQA - Visual Question Answering](./vqa-visual-question-answering.md)
- Colorization as a Proxy Task for Visual Understanding
- [Embodied Question Answering](./embodied-question-answering.md)
- [Context Encoders - Feature Learning by Inpainting](./context-encoders-feature-learning-by-inpainting.md)
- [Shuffle and Learn - Unsupervised Learning Using Temporal Order Verification](./shuffle-and-learn-unsupervised-learning-using-temporal-order-verification.md)
- Learning Image Representations Tied to Ego-Motion
- [Don't Just Assume; Look and Answer - Overcoming Priors for Visual Question Answering](./don-t-just-assume-look-and-answer-overcoming-priors-for-visual-question-answering.md)
- [Cross-lingual Language Model Pretraining](./cross-lingual-language-model-pretraining.md)
- [Stacked Cross Attention for Image-Text Matching](./stacked-cross-attention-for-image-text-matching.md)
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- Learning Features by Watching Objects Move
- nocaps - novel object captioning at scale
- [Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering](./dynamic-fusion-with-intra-and-inter-modality-attention-flow-for-visual-question-answering.md)
- ShapeCodes - Self-supervised Feature Learning by Lifting Views to Viewgrids
- [Aligning Books and Movies - Towards Story-Like Visual Explanations by Watching Movies and Reading Books](./aligning-books-and-movies-towards-story-like-visual-explanations-by-watching-movies-and-reading-books.md)
- [Conceptual Captions - A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning](./conceptual-captions-a-cleaned-hypernymed-image-alt-text-dataset-for-automatic-image-captioning.md)
- [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](./google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation.md)
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [Mask R-CNN](./mask-r-cnn.md)
- One billion word benchmark for measuring progress in statistical language modeling
- Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks
- [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](./faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.md)
- [Colorful Image Colorization](./colorful-image-colorization.md)
- ReferItGame - Referring to Objects in Photographs of Natural Scenes
- [From image descriptions to visual denotations - New similarity metrics for semantic inference over event descriptions](./from-image-descriptions-to-visual-denotations-new-similarity-metrics-for-semantic-inference-over-event-descriptions.md)
- [BERT has a Mouth, and It Must Speak - BERT as a Markov Random Field Language Model](./bert-has-a-mouth-and-it-must-speak-bert-as-a-markov-random-field-language-model.md)
- [ImageNet Large Scale Visual Recognition Challenge](./imagenet-large-scale-visual-recognition-challenge.md)
- Book Review - Mind as machine - a history of cognitive science
- [Microsoft COCO Captions - Data Collection and Evaluation Server](./microsoft-coco-captions-data-collection-and-evaluation-server.md)
