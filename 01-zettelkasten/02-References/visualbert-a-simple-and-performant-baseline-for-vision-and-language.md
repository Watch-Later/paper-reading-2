---
title: VisualBERT - A Simple and Performant Baseline for Vision and Language
authors:
- Liunian Harold Li
- Mark Yatskar
- Da Yin
- Cho-Jui Hsieh
- Kai-Wei Chang
fieldsOfStudy:
- Computer Science
meta_key: visualbert-a-simple-and-performant-baseline-for-vision-and-language
numCitedBy: 630
pdf_relpath: null
ref_count: 40
status: todo
tags:
- gen-from-ref
- paper
venue: ArXiv
year: 2019
---

# VisualBERT - A Simple and Performant Baseline for Vision and Language

## References

- [ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks](./vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks.md)
- [Deep Visual-Semantic Alignments for Generating Image Descriptions](./deep-visual-semantic-alignments-for-generating-image-descriptions.md)
- [MUREL - Multimodal Relational Reasoning for Visual Question Answering](./murel-multimodal-relational-reasoning-for-visual-question-answering.md)
- [Learning Conditioned Graph Structures for Interpretable Visual Question Answering](./learning-conditioned-graph-structures-for-interpretable-visual-question-answering.md)
- [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](./visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations.md)
- [VideoBERT - A Joint Model for Video and Language Representation Learning](./videobert-a-joint-model-for-video-and-language-representation-learning.md)
- [Deep Modular Co-Attention Networks for Visual Question Answering](./deep-modular-co-attention-networks-for-visual-question-answering.md)
- [From Recognition to Cognition - Visual Commonsense Reasoning](./from-recognition-to-cognition-visual-commonsense-reasoning.md)
- [Making the V in VQA Matter - Elevating the Role of Image Understanding in Visual Question Answering](./making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering.md)
- [Relation-Aware Graph Attention Network for Visual Question Answering](./relation-aware-graph-attention-network-for-visual-question-answering.md)
- [VQA - Visual Question Answering](./vqa-visual-question-answering.md)
- [Improving Language Understanding by Generative Pre-Training](./improving-language-understanding-by-generative-pre-training.md)
- Multimodal Transformer With Multi-View Visual Representation for Image Captioning
- [A Corpus for Reasoning about Natural Language Grounded in Photographs](./a-corpus-for-reasoning-about-natural-language-grounded-in-photographs.md)
- Flickr30k Entities - Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models
- [Language Models are Unsupervised Multitask Learners](./language-models-are-unsupervised-multitask-learners.md)
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](./bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering.md)
- [Attention is All you Need](./attention-is-all-you-need.md)
- [Towards VQA Models That Can Read](./towards-vqa-models-that-can-read.md)
- [Bilinear Attention Networks](./bilinear-attention-networks.md)
- What Does BERT Look at? An Analysis of BERT's Attention
- [Stacked Attention Networks for Image Question Answering](./stacked-attention-networks-for-image-question-answering.md)
- [Microsoft COCO - Common Objects in Context](./microsoft-coco-common-objects-in-context.md)
- [Conceptual Captions - A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning](./conceptual-captions-a-cleaned-hypernymed-image-alt-text-dataset-for-automatic-image-captioning.md)
- [A simple neural network module for relational reasoning](./a-simple-neural-network-module-for-relational-reasoning.md)
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [ImageNet Large Scale Visual Recognition Challenge](./imagenet-large-scale-visual-recognition-challenge.md)
- Analyzing Multi-Head Self-Attention - Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned
- [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](./faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.md)
- ReferItGame - Referring to Objects in Photographs of Natural Scenes
- [AllenNLP - A Deep Semantic Natural Language Processing Platform](./allennlp-a-deep-semantic-natural-language-processing-platform.md)
- Image retrieval using scene graphs
- [Deep Biaffine Attention for Neural Dependency Parsing](./deep-biaffine-attention-for-neural-dependency-parsing.md)
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](./google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation.md)
- [Pythia v0.1 - the Winning Entry to the VQA Challenge 2018](./pythia-v0-1-the-winning-entry-to-the-vqa-challenge-2018.md)
- Stanford typed dependencies manual
- [Microsoft COCO Captions - Data Collection and Evaluation Server](./microsoft-coco-captions-data-collection-and-evaluation-server.md)
