---
title: BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding

## References

- [Attention is All you Need](./attention-is-all-you-need.md)
- Dissecting Contextual Word Embeddings - Architecture and Representation
- Semi-Supervised Sequence Modeling with Cross-View Training
- [Semi-supervised sequence tagging with bidirectional language models](./semi-supervised-sequence-tagging-with-bidirectional-language-models.md)
- [Character-Level Language Modeling with Deeper Self-Attention](./character-level-language-modeling-with-deeper-self-attention.md)
- [QANet - Combining Local Convolution with Global Self-Attention for Reading Comprehension](./qanet-combining-local-convolution-with-global-self-attention-for-reading-comprehension.md)
- [GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](./glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding.md)
- [Skip-Thought Vectors](./skip-thought-vectors.md)
- MaskGAN - Better Text Generation via Filling in the ______
- [Contextual String Embeddings for Sequence Labeling](./contextual-string-embeddings-for-sequence-labeling.md)
- Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- U-Net - Machine Reading Comprehension with Unanswerable Questions
- [Bidirectional Attention Flow for Machine Comprehension](./bidirectional-attention-flow-for-machine-comprehension.md)
- [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](./recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank.md)
- [A unified architecture for natural language processing - deep neural networks with multitask learning](./a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning.md)
- [Universal Language Model Fine-tuning for Text Classification](./universal-language-model-fine-tuning-for-text-classification.md)
- [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](./google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation.md)
- One billion word benchmark for measuring progress in statistical language modeling
- [A Decomposable Attention Model for Natural Language Inference](./a-decomposable-attention-model-for-natural-language-inference.md)
- [TriviaQA - A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension](./triviaqa-a-large-scale-distantly-supervised-challenge-dataset-for-reading-comprehension.md)
- [Learned in Translation - Contextualized Word Vectors](./learned-in-translation-contextualized-word-vectors.md)
- [Supervised Learning of Universal Sentence Representations from Natural Language Inference Data](./supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data.md)
- [SemEval-2017 Task 1 - Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation](./semeval-2017-task-1-semantic-textual-similarity-multilingual-and-crosslingual-focused-evaluation.md)
- [A large annotated corpus for learning natural language inference](./a-large-annotated-corpus-for-learning-natural-language-inference.md)
- Semi-supervised Sequence Learning
- context2vec - Learning Generic Context Embedding with Bidirectional LSTM
- SWAG - A Large-Scale Adversarial Dataset for Grounded Commonsense Inference
- [SQuAD - 100,000+ Questions for Machine Comprehension of Text](./squad-100-000-questions-for-machine-comprehension-of-text.md)
- [A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference](./a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference.md)
- [Simple and Effective Multi-Paragraph Reading Comprehension](./simple-and-effective-multi-paragraph-reading-comprehension.md)
- Word Representations - A Simple and General Method for Semi-Supervised Learning
- [Learning Distributed Representations of Sentences from Unlabelled Data](./learning-distributed-representations-of-sentences-from-unlabelled-data.md)
- [An efficient framework for learning sentence representations](./an-efficient-framework-for-learning-sentence-representations.md)
- Domain Adaptation with Structural Correspondence Learning
- A Scalable Hierarchical Distributed Language Model
- Reinforced Mnemonic Reader for Machine Reading Comprehension
- [Distributed Representations of Sentences and Documents](./distributed-representations-of-sentences-and-documents.md)
- [GloVe - Global Vectors for Word Representation](./glove-global-vectors-for-word-representation.md)
- [How transferable are features in deep neural networks?](./how-transferable-are-features-in-deep-neural-networks.md)
- The Sixth PASCAL Recognizing Textual Entailment Challenge
- A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data
- [Neural Network Acceptability Judgments](./neural-network-acceptability-judgments.md)
- [Aligning Books and Movies - Towards Story-Like Visual Explanations by Watching Movies and Reading Books](./aligning-books-and-movies-towards-story-like-visual-explanations-by-watching-movies-and-reading-books.md)
- [Distributed Representations of Words and Phrases and their Compositionality](./distributed-representations-of-words-and-phrases-and-their-compositionality.md)
- [Extracting and composing robust features with denoising autoencoders](./extracting-and-composing-robust-features-with-denoising-autoencoders.md)
- The Seventh PASCAL Recognizing Textual Entailment Challenge
- Discourse-Based Objectives for Fast Unsupervised Sentence Representation Learning
- Automatically Constructing a Corpus of Sentential Paraphrases
- The PASCAL Recognising Textual Entailment Challenge
- The Winograd Schema Challenge
- [ImageNet - A large-scale hierarchical image database](./imagenet-a-large-scale-hierarchical-image-database.md)
- Class-Based n-gram Models of Natural Language
- [Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units](./bridging-nonlinearities-and-stochastic-regularizers-with-gaussian-error-linear-units.md)
- Introduction to the CoNLL-2003 Shared Task - Language-Independent Named Entity Recognition
- “Cloze Procedure” - A New Tool for Measuring Readability
