---
title: Semi-supervised Learning with Ladder Networks
authors:
- Antti Rasmus
- Mathias Berglund
- M. Honkala
- H. Valpola
- T. Raiko
fieldsOfStudy:
- Computer Science
meta_key: semi-supervised-learning-with-ladder-networks
numCitedBy: 1001
pdf_relpath: null
ref_count: 48
status: todo
tags:
- gen-from-ref
- paper
venue: NIPS
year: 2015
---

# Semi-supervised Learning with Ladder Networks

## References

- Pseudo-Label - The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks
- Lateral Connections in Denoising Autoencoders Support Supervised Learning
- From neural PCA to deep unsupervised learning
- Discriminative Unsupervised Feature Learning with Convolutional Neural Networks
- Exploring Semi-Supervised Learning With Ladder Networks
- Deconstructing the Ladder Network Architecture
- Techniques for Learning Binary Stochastic Feedforward Neural Networks
- [Semi-supervised Learning with Deep Generative Models](./semi-supervised-learning-with-deep-generative-models.md)
- Deep AutoRegressive Networks
- [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](./batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
- Deep learning via semi-supervised embedding
- [Reducing the Dimensionality of Data with Neural Networks](./reducing-the-dimensionality-of-data-with-neural-networks.md)
- Large-Scale Feature Learning With Spike-and-Slab Sparse Coding
- Distributional Smoothing by Virtual Adversarial Examples
- Semi-Supervised Learning
- Creating artificial neural networks that generalize
- Stacked What-Where Auto-encoders
- [Stacked Denoising Autoencoders - Learning Useful Representations in a Deep Network with a Local Denoising Criterion](./stacked-denoising-autoencoders-learning-useful-representations-in-a-deep-network-with-a-local-denoising-criterion.md)
- Multi-Prediction Deep Boltzmann Machines
- [Dropout - a simple way to prevent neural networks from overfitting](./dropout-a-simple-way-to-prevent-neural-networks-from-overfitting.md)
- [Adaptive deconvolutional networks for mid and high level feature learning](./adaptive-deconvolutional-networks-for-mid-and-high-level-feature-learning.md)
- [Striving for Simplicity - The All Convolutional Net](./striving-for-simplicity-the-all-convolutional-net.md)
- Semi-supervised Learning Using an Unsupervised Atlas
- Rule-Injection Hints as a Means of Improving Network Performance and Learning Time
- Semi-Supervised Learning
- [Maxout Networks](./maxout-networks.md)
- How Auto-Encoders Could Provide Credit Assignment in Deep Networks via Target Propagation
- The Manifold Tangent Classifier
- Semi-supervised learning of compact document representations with deep networks
- Higher Order Contractive Auto-Encoder
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- Distributional Smoothing with Virtual Adversarial Training
- Blocks and Fuel - Frameworks for deep learning
- [Explaining and Harnessing Adversarial Examples](./explaining-and-harnessing-adversarial-examples.md)
- Denoising autoencoder with modulated lateral connections learns invariant representations of natural images
- Generalized Denoising Auto-Encoders as Generative Models
- [Theano - new features and speed improvements](./theano-new-features-and-speed-improvements.md)
- Combining labeled and unlabeled data with co-training
- Partially labeled classification with Markov random walks
- The Value of Unlabeled Data for Classification Problems
- Iterative Reclassification Procedure for Constructing An Asymptotically Optimal Rule of Allocation in Discriminant-Analysis
- Denoising Source Separation
- and
- Statistical analysis of finite mixture distributions
- Machine Learning and Knowledge Discovery in Databases (ECML PKDD)
