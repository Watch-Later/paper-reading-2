---
title: Training Very Deep Networks
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# Training Very Deep Networks

## References

- [Highway Networks](./highway-networks.md)
- [Understanding the difficulty of training deep feedforward neural networks](./understanding-the-difficulty-of-training-deep-feedforward-neural-networks.md)
- Deep Networks with Internal Selective Attention through Feedback Connections
- Understanding Locally Competitive Networks
- [Network In Network](./network-in-network.md)
- On the Complexity of Neural Network Classifiers - A Comparison Between Shallow and Deep Architectures
- Random Walk Initialization for Training Very Deep Feedforward Networks
- Training Deep and Recurrent Networks with Hessian-Free Optimization
- [On the importance of initialization and momentum in deep learning](./on-the-importance-of-initialization-and-momentum-in-deep-learning.md)
- [FitNets - Hints for Thin Deep Nets](./fitnets-hints-for-thin-deep-nets.md)
- [Exact solutions to the nonlinear dynamics of learning in deep linear neural networks](./exact-solutions-to-the-nonlinear-dynamics-of-learning-in-deep-linear-neural-networks.md)
- On the Number of Linear Regions of Deep Neural Networks
- Deep Learning Made Easier by Linear Transformations in Perceptrons
- [Going deeper with convolutions](./going-deeper-with-convolutions.md)
- Feature Learning in Deep Neural Networks - Studies on Speech Recognition Tasks.
- [Deeply-Supervised Nets](./deeply-supervised-nets.md)
- [A Fast Learning Algorithm for Deep Belief Nets](./a-fast-learning-algorithm-for-deep-belief-nets.md)
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](./very-deep-convolutional-networks-for-large-scale-image-recognition.md)
- [Maxout Networks](./maxout-networks.md)
- [Striving for Simplicity - The All Convolutional Net](./striving-for-simplicity-the-all-convolutional-net.md)
- [ImageNet classification with deep convolutional neural networks](./imagenet-classification-with-deep-convolutional-neural-networks.md)
- [Multi-column deep neural networks for image classification](./multi-column-deep-neural-networks-for-image-classification.md)
- Learning Complex, Extended Sequences Using the Principle of History Compression
- [Grid Long Short-Term Memory](./grid-long-short-term-memory.md)
- [Flexible, High Performance Convolutional Neural Networks for Image Classification](./flexible-high-performance-convolutional-neural-networks-for-image-classification.md)
- [Long Short-Term Memory](./long-short-term-memory.md)
- Learning to Forget - Continual Prediction with LSTM
- Spatially-sparse convolutional neural networks
- [Generating Sequences With Recurrent Neural Networks](./generating-sequences-with-recurrent-neural-networks.md)
- Binding via Reconstruction Clustering
- Compete to Compute
- [Delving Deep into Rectifiers - Surpassing Human-Level Performance on ImageNet Classification](./delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification.md)
- Bridging Long Time Lags by Weight Guessing and \long Short Term Memory
- [Caffe - Convolutional Architecture for Fast Feature Embedding](./caffe-convolutional-architecture-for-fast-feature-embedding.md)
- On the Expressive Efficiency of Sum Product Networks
- [Identifying and attacking the saddle point problem in high-dimensional non-convex optimization](./identifying-and-attacking-the-saddle-point-problem-in-high-dimensional-non-convex-optimization.md)
- Computational limitations of small-depth circuits
- On the power of small-depth threshold circuits
- Untersuchungen zu dynamischen neuronalen Netzen
