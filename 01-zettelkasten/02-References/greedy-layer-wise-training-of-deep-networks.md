---
title: Greedy Layer-Wise Training of Deep Networks
authors:
- Yoshua Bengio
- Pascal Lamblin
- D. Popovici
- H. Larochelle
fieldsOfStudy:
- Computer Science
meta_key: greedy-layer-wise-training-of-deep-networks
numCitedBy: 3434
pdf_relpath: null
ref_count: 25
status: todo
tags:
- gen-from-ref
- paper
venue: NIPS
year: 2006
---

# Greedy Layer-Wise Training of Deep Networks

## References

- [A Fast Learning Algorithm for Deep Belief Nets](./a-fast-learning-algorithm-for-deep-belief-nets.md)
- Scaling learning algorithms towards AI
- Training MLPs layer by layer using an objective function for internal representations
- Convex Neural Networks
- The Curse of Highly Variable Functions for Local Kernel Machines
- A Monte Carlo EM Approach for Partially Observable Diffusion Processes - Theory and Applications to Neural Networks
- The Cascade-Correlation Learning Architecture
- [Reducing the Dimensionality of Data with Neural Networks](./reducing-the-dimensionality-of-data-with-neural-networks.md)
- [Training Products of Experts by Minimizing Contrastive Divergence](./training-products-of-experts-by-minimizing-contrastive-divergence.md)
- Many-Layered Learning
- The wake-sleep algorithm for unsupervised neural networks.
- Exponential Family Harmoniums with an Application to Information Retrieval
- Continuous restricted Boltzmann machine with an implementable training algorithm
- Computational limitations of small-depth circuits
- Circuit Complexity before the Dawn of the New Millennium
- Practical issues in temporal difference learning
