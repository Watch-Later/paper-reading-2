---
title: Improving Language Understanding by Generative Pre-Training
authors:
- Alec Radford
- Karthik Narasimhan
fieldsOfStudy:
- Computer Science
meta_key: improving-language-understanding-by-generative-pre-training
numCitedBy: 3533
pdf_relpath: null
ref_count: 76
status: todo
tags:
- gen-from-ref
- paper
venue: ''
year: 2018
---

# Improving Language Understanding by Generative Pre-Training

## References

- Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning
- [GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](./glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding.md)
- [A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference](./a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference.md)
- [Universal Language Model Fine-tuning for Text Classification](./universal-language-model-fine-tuning-for-text-classification.md)
- [Semi-supervised sequence tagging with bidirectional language models](./semi-supervised-sequence-tagging-with-bidirectional-language-models.md)
- A Simple but Tough-to-Beat Baseline for Sentence Embeddings
- [Supervised Learning of Universal Sentence Representations from Natural Language Inference Data](./supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data.md)
- [Unsupervised Pretraining for Sequence to Sequence Learning](./unsupervised-pretraining-for-sequence-to-sequence-learning.md)
- [Reasoning about Entailment with Neural Attention](./reasoning-about-entailment-with-neural-attention.md)
- [Skip-Thought Vectors](./skip-thought-vectors.md)
- A Compare-Propagate Architecture with Alignment Factorization for Natural Language Inference
- Unsupervised Machine Translation Using Monolingual Corpora Only
- UNSUPERVISED MACHINE TRANSLATION USING MONOLINGUAL CORPORA ONLY
- When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?
- [A large annotated corpus for learning natural language inference](./a-large-annotated-corpus-for-learning-natural-language-inference.md)
- Semi-Supervised Sequential Labeling and Segmentation Using Giga-Word Scale Unlabeled Data
- Semi-supervised Multitask Learning for Sequence Labeling
- [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](./recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank.md)
- [Natural Language Processing (Almost) from Scratch](./natural-language-processing-almost-from-scratch.md)
- [Learned in Translation - Contextualized Word Vectors](./learned-in-translation-contextualized-word-vectors.md)
- [A unified architecture for natural language processing - deep neural networks with multitask learning](./a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning.md)
- Semi-Supervised Learning for Natural Language
- [Attention is All you Need](./attention-is-all-you-need.md)
- [An efficient framework for learning sentence representations](./an-efficient-framework-for-learning-sentence-representations.md)
- [Teaching Machines to Read and Comprehend](./teaching-machines-to-read-and-comprehend.md)
- Constituency Parsing with a Self-Attentive Encoder
- [Distributed Representations of Sentences and Documents](./distributed-representations-of-sentences-and-documents.md)
- [Neural Machine Translation of Rare Words with Subword Units](./neural-machine-translation-of-rare-words-with-subword-units.md)
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- SciTaiL - A Textual Entailment Dataset from Science Question Answering
- [SQuAD - 100,000+ Questions for Machine Comprehension of Text](./squad-100-000-questions-for-machine-comprehension-of-text.md)
- [SemEval-2017 Task 1 - Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation](./semeval-2017-task-1-semantic-textual-similarity-multilingual-and-crosslingual-focused-evaluation.md)
- Multi-range Reasoning for Machine Comprehension
- Generating Wikipedia by Summarizing Long Sequences
- Semi-supervised Sequence Learning
- [GloVe - Global Vectors for Word Representation](./glove-global-vectors-for-word-representation.md)
- Roles of Pre-Training and Fine-Tuning in Context-Dependent DBN-HMMs for Real-World Speech Recognition
- Discourse-Based Objectives for Fast Unsupervised Sentence Representation Learning
- Semi-Supervised Text Classification Using EM
- Discriminative Improvements to Distributional Sentence Similarity
- Story Comprehension for Predicting What Happens Next
- [Convolutional Neural Networks for Sentence Classification](./convolutional-neural-networks-for-sentence-classification.md)
- The Sixth PASCAL Recognizing Textual Entailment Challenge
- [RACE - Large-scale ReAding Comprehension Dataset From Examinations](./race-large-scale-reading-comprehension-dataset-from-examinations.md)
- [Distributed Representations of Words and Phrases and their Compositionality](./distributed-representations-of-words-and-phrases-and-their-compositionality.md)
- ECNU at SemEval-2017 Task 1 - Leverage Kernel-based Traditional NLP features and Neural Networks to Build a Universal Model for Multilingual and Cross-lingual Semantic Textual Similarity
- [Aligning Books and Movies - Towards Story-Like Visual Explanations by Watching Movies and Reading Books](./aligning-books-and-movies-towards-story-like-visual-explanations-by-watching-movies-and-reading-books.md)
- A Simple and Effective Approach to the Story Cloze Test
- Fixing Weight Decay Regularization in Adam
- Learning Entity Representation for Entity Disambiguation
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- Greedy Layer-Wise Training of Deep Networks
- Towards Human-level Machine Reading Comprehension - Reasoning and Inference with Multiple Strategies
- [A Fast and Accurate Dependency Parser using Neural Networks](./a-fast-and-accurate-dependency-parser-using-neural-networks.md)
- Quora Question Pairs
- Stochastic Answer Networks for Natural Language Inference
- Resolving Complex Cases of Definite Pronouns - The Winograd Schema Challenge
- [A Fast Learning Algorithm for Deep Belief Nets](./a-fast-learning-algorithm-for-deep-belief-nets.md)
- [Extracting and composing robust features with denoising autoencoders](./extracting-and-composing-robust-features-with-denoising-autoencoders.md)
- Semi-Supervised Conditional Random Fields for Improved Sequence Segmentation and Labeling
- Automatically Constructing a Corpus of Sentential Paraphrases
- Split-Brain Autoencoders - Unsupervised Learning by Cross-Channel Prediction
- LSDSem 2017 Shared Task - The Story Cloze Test
- [Layer Normalization](./layer-normalization.md)
- Efficient Learning of Sparse Representations with an Energy-Based Model
- Semi-Supervised Text Classification Using EM
- GPU Kernels for Block-Sparse Weights
- [Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units](./bridging-nonlinearities-and-stochastic-regularizers-with-gaussian-error-linear-units.md)
- [A Stochastic Approximation Method](./a-stochastic-approximation-method.md)
- [Semi-Supervised Learning Literature Survey](./semi-supervised-learning-literature-survey.md)
- Why Does Unsupervised Pre-training Help Deep Learning?
