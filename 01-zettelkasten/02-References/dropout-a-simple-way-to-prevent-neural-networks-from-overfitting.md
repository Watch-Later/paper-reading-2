---
title: Dropout - a simple way to prevent neural networks from overfitting
authors:
- Nitish Srivastava
- Geoffrey E. Hinton
- A. Krizhevsky
- Ilya Sutskever
- R. Salakhutdinov
fieldsOfStudy:
- Computer Science
meta_key: dropout-a-simple-way-to-prevent-neural-networks-from-overfitting
numCitedBy: 28149
pdf_relpath: null
ref_count: 43
status: todo
tags:
- gen-from-ref
- paper
venue: J. Mach. Learn. Res.
year: 2014
---

# Dropout - a simple way to prevent neural networks from overfitting

## References

- Improving Neural Networks with Dropout
- [Learning Multiple Layers of Features from Tiny Images](./learning-multiple-layers-of-features-from-tiny-images.md)
- Fast dropout training
- [ImageNet classification with deep convolutional neural networks](./imagenet-classification-with-deep-convolutional-neural-networks.md)
- [A Fast Learning Algorithm for Deep Belief Nets](./a-fast-learning-algorithm-for-deep-belief-nets.md)
- Learning with Marginalized Corrupted Features
- Simplifying Neural Networks by Soft Weight-Sharing
- Dropout Training as Adaptive Regularization
- Deep Boltzmann Machines
- Bayesian Learning for Neural Networks
- [Stacked Denoising Autoencoders - Learning Useful Representations in a Deep Network with a Local Denoising Criterion](./stacked-denoising-autoencoders-learning-useful-representations-in-a-deep-network-with-a-local-denoising-criterion.md)
- Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine
- [Acoustic Modeling Using Deep Belief Networks](./acoustic-modeling-using-deep-belief-networks.md)
- [Practical Bayesian Optimization of Machine Learning Algorithms](./practical-bayesian-optimization-of-machine-learning-algorithms.md)
- Stochastic Pooling for Regularization of Deep Convolutional Neural Networks
- Best practices for convolutional neural networks applied to visual document analysis
- Learning to classify with missing and corrupted features
- [Reducing the Dimensionality of Data with Neural Networks](./reducing-the-dimensionality-of-data-with-neural-networks.md)
- [Maxout Networks](./maxout-networks.md)
- [Reading Digits in Natural Images with Unsupervised Feature Learning](./reading-digits-in-natural-images-with-unsupervised-feature-learning.md)
- [Extracting and composing robust features with denoising autoencoders](./extracting-and-composing-robust-features-with-denoising-autoencoders.md)
- Nightmare at test time - robust learning by feature deletion
- Convolutional neural networks applied to house numbers digit classification
- What is the best multi-stage architecture for object recognition?
- Marginalized Denoising Autoencoders for Domain Adaptation
- Backpropagation Applied to Handwritten Zip Code Recognition
- Bayesian probabilistic matrix factorization using Markov chain Monte Carlo
- [The Kaldi Speech Recognition Toolkit](./the-kaldi-speech-recognition-toolkit.md)
- [Regression Shrinkage and Selection via the Lasso](./regression-shrinkage-and-selection-via-the-lasso.md)
- High-dimensional signature compression for large-scale image classification
- CUDAMat - a CUDA-based matrix class for Python
- Bayesian prediction of tissue-regulated splicing using RNA sequence and cellular context
- Rank, Trace-Norm and Max-Norm
- Sex, mixability, and modularity
- The Stability of Inverse Problems
- IEEE Workshop on automatic speech recognition and understanding
