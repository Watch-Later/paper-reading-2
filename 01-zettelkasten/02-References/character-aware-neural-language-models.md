---
title: Character-Aware Neural Language Models
authors:
- Yoon Kim
- Yacine Jernite
- D. Sontag
- Alexander M. Rush
fieldsOfStudy:
- Computer Science
meta_key: character-aware-neural-language-models
numCitedBy: 1428
pdf_relpath: null
ref_count: 83
status: todo
tags:
- gen-from-ref
- paper
venue: AAAI
year: 2016
---

# Character-Aware Neural Language Models

## References

- SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS
- Learning Character-level Representations for Part-of-Speech Tagging
- Boosting Named Entity Recognition with Neural Character Embeddings
- [LSTM Neural Networks for Language Modeling](./lstm-neural-networks-for-language-modeling.md)
- genCNN - A Convolutional Architecture for Word Sequence Prediction
- Context dependent recurrent neural network language model
- Co-learning of Word Representations and Morpheme Representations
- Better Word Representations with Recursive Neural Networks for Morphology
- [A Convolutional Neural Network for Modelling Sentences](./a-convolutional-neural-network-for-modelling-sentences.md)
- [Sequence to Sequence Learning with Neural Networks](./sequence-to-sequence-learning-with-neural-networks.md)
- Improved Transition-based Parsing by Modeling Characters instead of Words with LSTMs
- [Recurrent neural network based language model](./recurrent-neural-network-based-language-model.md)
- Hierarchical Probabilistic Neural Network Language Model
- Finding Function in Form - Compositional Character Models for Open Vocabulary Word Representation
- Probabilistic modelling of morphologically rich languages
- [Generating Text with Recurrent Neural Networks](./generating-text-with-recurrent-neural-networks.md)
- [Linguistic Regularities in Continuous Space Word Representations](./linguistic-regularities-in-continuous-space-word-representations.md)
- Compositional Morphology for Word Representations and Language Modelling
- A Neural Probabilistic Language Model
- Factored Language Models and Generalized Parallel Backoff
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](./learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation.md)
- [Natural Language Processing (Almost) from Scratch](./natural-language-processing-almost-from-scratch.md)
- [Convolutional Neural Networks for Sentence Classification](./convolutional-neural-networks-for-sentence-classification.md)
- A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval
- Factored Neural Language Models
- [Character-level Convolutional Networks for Text Classification](./character-level-convolutional-networks-for-text-classification.md)
- Language modeling with sum-product networks
- How to Construct Deep Recurrent Neural Networks
- The Fixed-Size Ordinally-Forgetting Encoding Method for Neural Network Language Models
- [Efficient Estimation of Word Representations in Vector Space](./efficient-estimation-of-word-representations-in-vector-space.md)
- [Recurrent Neural Network Regularization](./recurrent-neural-network-regularization.md)
- Text Understanding from Scratch
- Empirical Evaluation and Combination of Advanced Language Modeling Techniques
- [ImageNet classification with deep convolutional neural networks](./imagenet-classification-with-deep-convolutional-neural-networks.md)
- Unsupervised models for morpheme segmentation and morphology learning
- Three new graphical models for statistical language modelling
- Molding CNNs for text - non-linear, non-consecutive convolutions
- N-gram Counts and Language Models from the Common Crawl
- [Generating Sequences With Recurrent Neural Networks](./generating-sequences-with-recurrent-neural-networks.md)
- [Long Short-Term Memory](./long-short-term-memory.md)
- Building a Large Annotated Corpus of English - The Penn Treebank
- Learning long-term dependencies with gradient descent is difficult
- [Improving neural networks by preventing co-adaptation of feature detectors](./improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors.md)
- [Training Very Deep Networks](./training-very-deep-networks.md)
- Backpropagation Through Time - What It Does and How to Do It
- Handwritten Digit Recognition with a Back-Propagation Network
- Indexing by Latent Semantic Analysis
- An empirical study of smoothing techniques for language modeling
