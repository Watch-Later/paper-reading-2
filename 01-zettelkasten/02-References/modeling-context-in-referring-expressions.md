---
title: Modeling Context in Referring Expressions
authors:
- Licheng Yu
- Patrick Poirson
- Shan Yang
- A. Berg
- Tamara L. Berg
fieldsOfStudy:
- Computer Science
meta_key: modeling-context-in-referring-expressions
numCitedBy: 378
pdf_relpath: null
ref_count: 42
status: todo
tags:
- gen-from-ref
- paper
venue: ECCV
year: 2016
---

# Modeling Context in Referring Expressions

## References

- [Generation and Comprehension of Unambiguous Object Descriptions](./generation-and-comprehension-of-unambiguous-object-descriptions.md)
- ReferItGame - Referring to Objects in Photographs of Natural Scenes
- Learning Distributions over Logical Forms for Referring Expression Generation
- The Use of Spatial Relations in Referring Expression Generation
- Generating Referring Expressions Using Perceptual Groups
- [From captions to visual concepts and back](./from-captions-to-visual-concepts-and-back.md)
- [Grounding of Textual Phrases in Images by Reconstruction](./grounding-of-textual-phrases-in-images-by-reconstruction.md)
- Grounded Compositional Semantics for Finding and Describing Images with Sentences
- Framing Image Description as a Ranking Task - Data, Models and Evaluation Metrics (Extended Abstract)
- Computational Generation of Referring Expressions - A Survey
- BabyTalk - Understanding and Generating Simple Image Descriptions
- [Show, Attend and Tell - Neural Image Caption Generation with Visual Attention](./show-attend-and-tell-neural-image-caption-generation-with-visual-attention.md)
- [Natural Language Object Retrieval](./natural-language-object-retrieval.md)
- Every Picture Tells a Story - Generating Sentences from Images
- [Show and tell - A neural image caption generator](./show-and-tell-a-neural-image-caption-generator.md)
- [Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models](./unifying-visual-semantic-embeddings-with-multimodal-neural-language-models.md)
- Natural Reference to Objects in a Visual Domain
- [Microsoft COCO - Common Objects in Context](./microsoft-coco-common-objects-in-context.md)
- [Inside-Outside Net - Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks](./inside-outside-net-detecting-objects-in-context-with-skip-pooling-and-recurrent-neural-networks.md)
- Visalogy - Answering Visual Analogy Questions
- Learning Attribute Selections for Non-Pronominal Expressions
- [DenseCap - Fully Convolutional Localization Networks for Dense Captioning](./densecap-fully-convolutional-localization-networks-for-dense-captioning.md)
- Typicality and Object Reference
- Incremental Generation of Spatial Referring Expressions in Situated Dialog
- DeePM - A Deep Part-Based Model for Object Detection and Semantic Part Localization
- Watching the eyes when talking about size - An investigation of message formulation and utterance planning
- Understanding natural language
- [Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)](./deep-captioning-with-multimodal-recurrent-neural-networks-m-rnn.md)
- [Long-term recurrent convolutional networks for visual recognition and description](./long-term-recurrent-convolutional-networks-for-visual-recognition-and-description.md)
- Im2Text - Describing Images Using 1 Million Captioned Photographs
- [SSD - Single Shot MultiBox Detector](./ssd-single-shot-multibox-detector.md)
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](./very-deep-convolutional-networks-for-large-scale-image-recognition.md)
- Scalable Object Detection Using Deep Neural Networks
- [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](./faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.md)
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [LSTM - A Search Space Odyssey](./lstm-a-search-space-odyssey.md)
- [ImageNet Large Scale Visual Recognition Challenge](./imagenet-large-scale-visual-recognition-challenge.md)
- [Fast R-CNN](./fast-r-cnn.md)
- [Logic and Conversation](./logic-and-conversation.md)
- Generating Expressions that Refer to Visible Objects
