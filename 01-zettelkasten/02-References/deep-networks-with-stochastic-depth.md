---
title: Deep Networks with Stochastic Depth
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# Deep Networks with Stochastic Depth

## References

- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [Deeply-Supervised Nets](./deeply-supervised-nets.md)
- Gradual DropIn of Layers to Train Very Deep Neural Networks
- [On the importance of initialization and momentum in deep learning](./on-the-importance-of-initialization-and-momentum-in-deep-learning.md)
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](./very-deep-convolutional-networks-for-large-scale-image-recognition.md)
- [Striving for Simplicity - The All Convolutional Net](./striving-for-simplicity-the-all-convolutional-net.md)
- [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](./batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
- [Understanding the difficulty of training deep feedforward neural networks](./understanding-the-difficulty-of-training-deep-feedforward-neural-networks.md)
- [ImageNet classification with deep convolutional neural networks](./imagenet-classification-with-deep-convolutional-neural-networks.md)
- [Dropout - a simple way to prevent neural networks from overfitting](./dropout-a-simple-way-to-prevent-neural-networks-from-overfitting.md)
- Generalizing Pooling Functions in Convolutional Neural Networks - Mixed, Gated, and Tree
- [Network In Network](./network-in-network.md)
- [Training Very Deep Networks](./training-very-deep-networks.md)
- [Identity Mappings in Deep Residual Networks](./identity-mappings-in-deep-residual-networks.md)
- [Learning Multiple Layers of Features from Tiny Images](./learning-multiple-layers-of-features-from-tiny-images.md)
- Why Does Unsupervised Pre-training Help Deep Learning?
- Recurrent convolutional neural network for object recognition
- [Going deeper with convolutions](./going-deeper-with-convolutions.md)
- Fractional Max-Pooling
- Scalable Bayesian Optimization Using Deep Neural Networks
- [Regularization of Neural Networks using DropConnect](./regularization-of-neural-networks-using-dropconnect.md)
- [OverFeat - Integrated Recognition, Localization and Detection using Convolutional Networks](./overfeat-integrated-recognition-localization-and-detection-using-convolutional-networks.md)
- [Maxout Networks](./maxout-networks.md)
- Learning Activation Functions to Improve Deep Neural Networks
- [Reading Digits in Natural Images with Unsupervised Feature Learning](./reading-digits-in-natural-images-with-unsupervised-feature-learning.md)
- The Cascade-Correlation Learning Architecture
- Learning long-term dependencies with gradient descent is difficult
- [ImageNet - A large-scale hierarchical image database](./imagenet-a-large-scale-hierarchical-image-database.md)
- [Rectified Linear Units Improve Restricted Boltzmann Machines](./rectified-linear-units-improve-restricted-boltzmann-machines.md)
- Computational limitations of small-depth circuits
- [Torch7 - A Matlab-like Environment for Machine Learning](./torch7-a-matlab-like-environment-for-machine-learning.md)
- On the power of small-depth threshold circuits
