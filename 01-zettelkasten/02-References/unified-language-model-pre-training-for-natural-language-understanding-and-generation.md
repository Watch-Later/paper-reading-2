---
title: Unified Language Model Pre-training for Natural Language Understanding and Generation
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# Unified Language Model Pre-training for Natural Language Understanding and Generation

## References

- Cross-Lingual Natural Language Generation via Pre-Training
- Pre-trained language model representations for language generation
- [Multi-Task Deep Neural Networks for Natural Language Understanding](./multi-task-deep-neural-networks-for-natural-language-understanding.md)
- [Language Models are Unsupervised Multitask Learners](./language-models-are-unsupervised-multitask-learners.md)
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- [MASS - Masked Sequence to Sequence Pre-training for Language Generation](./mass-masked-sequence-to-sequence-pre-training-for-language-generation.md)
- [Improving Language Understanding by Generative Pre-Training](./improving-language-understanding-by-generative-pre-training.md)
- [GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](./glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding.md)
- Text Summarization with Pretrained Encoders
- [Attention is All you Need](./attention-is-all-you-need.md)
- [A Deep Reinforced Model for Abstractive Summarization](./a-deep-reinforced-model-for-abstractive-summarization.md)
- [Universal Language Model Fine-tuning for Text Classification](./universal-language-model-fine-tuning-for-text-classification.md)
- Paragraph-level Neural Question Generation with Maxout Pointer and Gated Self-attention Networks
- [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](./recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank.md)
- Learning and Evaluating General Linguistic Intelligence
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- Learning to Ask - Neural Question Generation for Reading Comprehension
- [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](./google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation.md)
- [A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference](./a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference.md)
- [Get To The Point - Summarization with Pointer-Generator Networks](./get-to-the-point-summarization-with-pointer-generator-networks.md)
- [A Neural Attention Model for Abstractive Sentence Summarization](./a-neural-attention-model-for-abstractive-sentence-summarization.md)
- Addressing Semantic Drift in Question Generation for Semi-Supervised Question Answering
- Bottom-Up Abstractive Summarization
- [SemEval-2017 Task 1 - Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation](./semeval-2017-task-1-semantic-textual-similarity-multilingual-and-crosslingual-focused-evaluation.md)
- Cloze-driven Pretraining of Self-attention Networks
- Harvesting Paragraph-level Question-Answer Pairs from Wikipedia
- Neural Question Generation from Text - A Preliminary Study
- Semi-supervised Sequence Learning
- Conversing by Reading - Contentful Neural Conversation with On-demand Machine Reading
- [SQuAD - 100,000+ Questions for Machine Comprehension of Text](./squad-100-000-questions-for-machine-comprehension-of-text.md)
- CoQA - A Conversational Question Answering Challenge
- Neural Document Summarization by Jointly Learning to Score and Select Sentences
- Fine-tune BERT for Extractive Summarization
- [Know What You Don't Know - Unanswerable Questions for SQuAD](./know-what-you-don-t-know-unanswerable-questions-for-squad.md)
- The Sixth PASCAL Recognizing Textual Entailment Challenge
- Read + Verify - Machine Reading Comprehension with Unanswerable Questions
- Cluster-based beam search for pointer-generator chatbot grounded by knowledge
- Grounded Response Generation Task at DSTC7
- Retrieve, Rerank and Rewrite - Soft Template Based Neural Summarization
- [Rethinking the Inception Architecture for Computer Vision](./rethinking-the-inception-architecture-for-computer-vision.md)
- [OpenNMT - Open-Source Toolkit for Neural Machine Translation](./opennmt-open-source-toolkit-for-neural-machine-translation.md)
- The Seventh PASCAL Recognizing Textual Entailment Challenge
- [Neural Network Acceptability Judgments](./neural-network-acceptability-judgments.md)
- [Aligning Books and Movies - Towards Story-Like Visual Explanations by Watching Movies and Reading Books](./aligning-books-and-movies-towards-story-like-visual-explanations-by-watching-movies-and-reading-books.md)
- The Second PASCAL Recognising Textual Entailment Challenge
- Neural Approaches to Conversational AI
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- [Long Short-Term Memory](./long-short-term-memory.md)
- [ROUGE - A Package for Automatic Evaluation of Summaries](./rouge-a-package-for-automatic-evaluation-of-summaries.md)
- Automatically Constructing a Corpus of Sentential Paraphrases
- The PASCAL Recognising Textual Entailment Challenge
- [BERT has a Mouth, and It Must Speak - BERT as a Markov Random Field Language Model](./bert-has-a-mouth-and-it-must-speak-bert-as-a-markov-random-field-language-model.md)
- The Winograd Schema Challenge
- [Gaussian Error Linear Units (GELUs)](./gaussian-error-linear-units-gelus.md)
- In Advances in Neural Information Processing Systems
- “Cloze Procedure” - A New Tool for Measuring Readability
