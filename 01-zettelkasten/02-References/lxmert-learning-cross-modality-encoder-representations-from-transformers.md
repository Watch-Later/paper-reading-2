---
title: LXMERT - Learning Cross-Modality Encoder Representations from Transformers
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# LXMERT - Learning Cross-Modality Encoder Representations from Transformers

## References

- [ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks](./vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks.md)
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- Multimodal Unified Attention Networks for Vision-and-Language Interactions
- [VideoBERT - A Joint Model for Video and Language Representation Learning](./videobert-a-joint-model-for-video-and-language-representation-learning.md)
- [Attention is All you Need](./attention-is-all-you-need.md)
- [Visual7W - Grounded Question Answering in Images](./visual7w-grounded-question-answering-in-images.md)
- Multi-Modality Latent Interaction Network for Visual Question Answering
- [VisualBERT - A Simple and Performant Baseline for Vision and Language](./visualbert-a-simple-and-performant-baseline-for-vision-and-language.md)
- [Improving Language Understanding by Generative Pre-Training](./improving-language-understanding-by-generative-pre-training.md)
- [Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering](./dynamic-fusion-with-intra-and-inter-modality-attention-flow-for-visual-question-answering.md)
- [Deep Modular Co-Attention Networks for Visual Question Answering](./deep-modular-co-attention-networks-for-visual-question-answering.md)
- exBERT - A Visual Analysis Tool to Explore Learned Representations in Transformer Models
- [Beyond Bilinear - Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering](./beyond-bilinear-generalized-multimodal-factorized-high-order-pooling-for-visual-question-answering.md)
- [Making the V in VQA Matter - Elevating the Role of Image Understanding in Visual Question Answering](./making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering.md)
- [Bilinear Attention Networks](./bilinear-attention-networks.md)
- [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](./visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations.md)
- [FiLM - Visual Reasoning with a General Conditioning Layer](./film-visual-reasoning-with-a-general-conditioning-layer.md)
- [Hierarchical Question-Image Co-Attention for Visual Question Answering](./hierarchical-question-image-co-attention-for-visual-question-answering.md)
- [GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](./glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding.md)
- [Cross-lingual Language Model Pretraining](./cross-lingual-language-model-pretraining.md)
- [Learning to Reason - End-to-End Module Networks for Visual Question Answering](./learning-to-reason-end-to-end-module-networks-for-visual-question-answering.md)
- [Neural Machine Translation by Jointly Learning to Align and Translate](./neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
- GQA - a new dataset for compositional question answering over real-world images
- Cycle-Consistency for Robust Visual Question Answering
- [Show, Attend and Tell - Neural Image Caption Generation with Visual Attention](./show-attend-and-tell-neural-image-caption-generation-with-visual-attention.md)
- [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](./google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation.md)
- [Bidirectional Attention Flow for Machine Comprehension](./bidirectional-attention-flow-for-machine-comprehension.md)
- [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](./bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering.md)
- [VQA - Visual Question Answering](./vqa-visual-question-answering.md)
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation](./rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.md)
- [A Corpus for Reasoning about Natural Language Grounded in Photographs](./a-corpus-for-reasoning-about-natural-language-grounded-in-photographs.md)
- [Going deeper with convolutions](./going-deeper-with-convolutions.md)
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](./very-deep-convolutional-networks-for-large-scale-image-recognition.md)
- [Pythia v0.1 - the Winning Entry to the VQA Challenge 2018](./pythia-v0-1-the-winning-entry-to-the-vqa-challenge-2018.md)
- Gated Feedback Recurrent Neural Networks
- [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](./faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.md)
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- [SQuAD - 100,000+ Questions for Machine Comprehension of Text](./squad-100-000-questions-for-machine-comprehension-of-text.md)
- [Microsoft COCO - Common Objects in Context](./microsoft-coco-common-objects-in-context.md)
- [ImageNet - A large-scale hierarchical image database](./imagenet-a-large-scale-hierarchical-image-database.md)
- [Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units](./bridging-nonlinearities-and-stochastic-regularizers-with-gaussian-error-linear-units.md)
