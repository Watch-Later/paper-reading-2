---
title: Enriching Word Vectors with Subword Information
authors:
- Piotr Bojanowski
- Edouard Grave
- Armand Joulin
- Tomas Mikolov
fieldsOfStudy:
- Computer Science
meta_key: enriching-word-vectors-with-subword-information
numCitedBy: 6589
pdf_relpath: null
ref_count: 55
status: todo
tags:
- gen-from-ref
- paper
venue: Transactions of the Association for Computational Linguistics
year: 2017
---

# Enriching Word Vectors with Subword Information

## References

- Better Word Representations with Recursive Neural Networks for Morphology
- Co-learning of Word Representations and Morpheme Representations
- Learning Character-level Representations for Part-of-Speech Tagging
- Joint Learning of Character and Word Embeddings
- [Efficient Estimation of Word Representations in Vector Space](./efficient-estimation-of-word-representations-in-vector-space.md)
- [Distributed Representations of Words and Phrases and their Compositionality](./distributed-representations-of-words-and-phrases-and-their-compositionality.md)
- KNET - A General Framework for Learning Word Embedding Using Morphological Knowledge
- Finding Function in Form - Compositional Character Models for Open Vocabulary Word Representation
- Word Embeddings Go to Italy - A Comparison of Models and Training Datasets
- Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models
- [Neural Machine Translation of Rare Words with Subword Units](./neural-machine-translation-of-rare-words-with-subword-units.md)
- Letter N-Gram-based Input Encoding for Continuous Space Language Models
- [Character-Aware Neural Language Models](./character-aware-neural-language-models.md)
- Compositional Morphology for Word Representations and Language Modelling
- Multilingual Reliability and “Semantic” Structure of Continuous Word Spaces
- Distributional Memory - A General Framework for Corpus-Based Semantics
- Producing high-dimensional semantic spaces from lexical co-occurrence
- [Charagram - Embedding Words and Sentences via Character n-grams](./charagram-embedding-words-and-sentences-via-character-n-grams.md)
- Alternative structures for character-level RNNs
- Morphological Word-Embeddings
- [A unified architecture for natural language processing - deep neural networks with multitask learning](./a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning.md)
- Comparison of Semantic Similarity for Different Languages Using the Google n-gram Corpus and Second-Order Co-occurrence Measures
- Normalizing tweets with edit scripts and recurrent neural embeddings
- SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS
- Dimensions of meaning
- Morphology-based and sub-word language modeling for Turkish speech recognition
- Improved Transition-based Parsing by Modeling Characters instead of Words with LSTMs
- Compositional-ly Derived Representations of Morphologically Complex Words in Distributional Semantics
- Factored Neural Language Models
- Word Space
- Human and Machine Judgements for Russian Semantic Relatedness
- From Frequency to Meaning - Vector Space Models of Semantics
- New word analogy corpus for exploring embeddings of Czech words
- Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts
- Unsupervised Morphology Induction Using Word Embeddings
- [Generating Text with Recurrent Neural Networks](./generating-text-with-recurrent-neural-networks.md)
- Using the Structure of a Conceptual Network in Computing Semantic Relatedness
- Indexing by Latent Semantic Analysis
- Distributional Structure
- [Character-level Convolutional Networks for Text Classification](./character-level-convolutional-networks-for-text-classification.md)
- Cross-lingual Semantic Relatedness Using Encyclopedic Knowledge
- Automatically Creating Datasets for Measures of Semantic Relatedness
- [Generating Sequences With Recurrent Neural Networks](./generating-sequences-with-recurrent-neural-networks.md)
- Learning representations by back-propagating errors
- Placing search in context - the concept revisited
- Neurocomputing - Foundations of Research
- [Hogwild - A Lock-Free Approach to Parallelizing Stochastic Gradient Descent](./hogwild-a-lock-free-approach-to-parallelizing-stochastic-gradient-descent.md)
- Identifying Opportunities for Valuable Encounters - Toward Context-Aware Social Matching Systems
- The Proof and Measurement of Association between Two Things.
