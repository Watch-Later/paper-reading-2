---
title: Grid Long Short-Term Memory
authors:
- Nal Kalchbrenner
- Ivo Danihelka
- A. Graves
fieldsOfStudy:
- Computer Science
meta_key: grid-long-short-term-memory
numCitedBy: 311
pdf_relpath: null
ref_count: 52
status: todo
tags:
- gen-from-ref
- paper
venue: ICLR
year: 2016
---

# Grid Long Short-Term Memory

## References

- [Sequence to Sequence Learning with Neural Networks](./sequence-to-sequence-learning-with-neural-networks.md)
- [Long Short-Term Memory](./long-short-term-memory.md)
- [LSTM - A Search Space Odyssey](./lstm-a-search-space-odyssey.md)
- Learning to Execute
- [Generating Text with Recurrent Neural Networks](./generating-text-with-recurrent-neural-networks.md)
- [Speech recognition with deep recurrent neural networks](./speech-recognition-with-deep-recurrent-neural-networks.md)
- Gated Feedback Recurrent Neural Networks
- [Network In Network](./network-in-network.md)
- [Show and tell - A neural image caption generator](./show-and-tell-a-neural-image-caption-generator.md)
- [Generating Sequences With Recurrent Neural Networks](./generating-sequences-with-recurrent-neural-networks.md)
- [Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models](./unifying-visual-semantic-embeddings-with-multimodal-neural-language-models.md)
- [Neural Machine Translation by Jointly Learning to Align and Translate](./neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
- Multi-dimensional Recurrent Neural Networks
- Supervised Sequence Labelling with Recurrent Neural Networks
- Learning long-term dependencies with gradient descent is difficult
- Convolutional Kernel Networks
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](./learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation.md)
- [Multi-column deep neural networks for image classification](./multi-column-deep-neural-networks-for-image-classification.md)
- Spatially-sparse convolutional neural networks
- [Recurrent Continuous Translation Models](./recurrent-continuous-translation-models.md)
- Fractional Max-Pooling
- cdec - A Decoder, Alignment, and Learning Framework for Finite- State and Context-Free Translation Models
- Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks
- [Gradient-based learning applied to document recognition](./gradient-based-learning-applied-to-document-recognition.md)
- [Deeply-Supervised Nets](./deeply-supervised-nets.md)
- ReNet - A Recurrent Neural Network Based Alternative to Convolutional Networks
- Best practices for convolutional neural networks applied to visual document analysis
- [Regularization of Neural Networks using DropConnect](./regularization-of-neural-networks-using-dropconnect.md)
- [Maxout Networks](./maxout-networks.md)
- Gradient Flow in Recurrent Nets - the Difficulty of Learning Long-Term Dependencies
- [Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](./adaptive-subgradient-methods-for-online-learning-and-stochastic-optimization.md)
- [Rectified Linear Units Improve Restricted Boltzmann Machines](./rectified-linear-units-improve-restricted-boltzmann-machines.md)
- Artificial Neural Networks
- [Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks](./under-review-as-a-conference-paper-at-iclr-2017-delving-into-transferable-adversarial-ex-amples-and-black-box-attacks.md)
- Perceptrons - an introduction to computational geometry
- Untersuchungen zu dynamischen neuronalen Netzen
- Solving the N-bit parity problem using neural networks
