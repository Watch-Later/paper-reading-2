---
title: Revealing the Dark Secrets of BERT
authors:
- Olga Kovaleva
- Alexey Romanov
- Anna Rogers
- Anna Rumshisky
fieldsOfStudy:
- Computer Science
meta_key: revealing-the-dark-secrets-of-bert
numCitedBy: 290
pdf_relpath: null
ref_count: 28
status: todo
tags:
- gen-from-ref
- paper
venue: EMNLP
year: 2019
---

# Revealing the Dark Secrets of BERT

## References

- Are Sixteen Heads Really Better than One?
- Analyzing Multi-Head Self-Attention - Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- What Does BERT Learn about the Structure of Language?
- [Attention is All you Need](./attention-is-all-you-need.md)
- [SuperGLUE - A Stickier Benchmark for General-Purpose Language Understanding Systems](./superglue-a-stickier-benchmark-for-general-purpose-language-understanding-systems.md)
- Rethinking Complex Neural Network Architectures for Document Classification
- [How transferable are features in deep neural networks?](./how-transferable-are-features-in-deep-neural-networks.md)
- The Lottery Ticket Hypothesis - Finding Sparse, Trainable Neural Networks
- Linguistic Knowledge and Transferability of Contextual Representations
- The Importance of Being Recurrent for Modeling Hierarchical Structure
- [GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](./glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding.md)
- Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures
- [SQuAD - 100,000+ Questions for Machine Comprehension of Text](./squad-100-000-questions-for-machine-comprehension-of-text.md)
- Lessons from Natural Language Inference in the Clinical Domain
- [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](./recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank.md)
- [SemEval-2017 Task 1 - Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation](./semeval-2017-task-1-semantic-textual-similarity-multilingual-and-crosslingual-focused-evaluation.md)
- [A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference](./a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference.md)
- Assessing BERT's Syntactic Abilities
- The Berkeley FrameNet Project
- Automatically Constructing a Corpus of Sentential Paraphrases
- The empirical base of linguistics - Grammaticality judgments and linguistic methodology
- Pay Less Attention with Lightweight and Dynamic Convolutions
