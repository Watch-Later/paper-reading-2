---
title: Outrageously Large Neural Networks - The Sparsely-Gated Mixture-of-Experts Layer
authors:
- Noam M. Shazeer
- Azalia Mirhoseini
- Krzysztof Maziarz
- Andy Davis
- Quoc V. Le
- Geoffrey E. Hinton
- J. Dean
fieldsOfStudy:
- Computer Science
meta_key: outrageously-large-neural-networks-the-sparsely-gated-mixture-of-experts-layer
numCitedBy: 862
pdf_relpath: null
ref_count: 45
status: todo
tags:
- gen-from-ref
- paper
venue: ICLR
year: 2017
---

# Outrageously Large Neural Networks - The Sparsely-Gated Mixture-of-Experts Layer

## References

- Exponentially Increasing the Capacity-to-Computation Ratio for Conditional Computation in Deep Learning
- Learning Factored Representations in a Deep Mixture of Experts
- Low-Rank Approximations for Conditional Feedforward Computation in Deep Neural Networks
- Conditional Computation in Neural Networks for faster models
- Expert Gate - Lifelong Learning with a Network of Experts
- Dynamic Capacity Networks
- [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](./batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
- [Building high-level features using large scale unsupervised learning](./building-high-level-features-using-large-scale-unsupervised-learning.md)
- [Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation](./deep-recurrent-models-with-fast-forward-connections-for-neural-machine-translation.md)
- [Sequence to Sequence Learning with Neural Networks](./sequence-to-sequence-learning-with-neural-networks.md)
- [Exploring the Limits of Language Modeling](./exploring-the-limits-of-language-modeling.md)
- [ImageNet classification with deep convolutional neural networks](./imagenet-classification-with-deep-convolutional-neural-networks.md)
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [Long short-term memory recurrent neural network architectures for large scale acoustic modeling](./long-short-term-memory-recurrent-neural-network-architectures-for-large-scale-acoustic-modeling.md)
- [Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation](./estimating-or-propagating-gradients-through-stochastic-neurons-for-conditional-computation.md)
- One billion word benchmark for measuring progress in statistical language modeling
- Deep Sequential Neural Networks Deep Sequential Neural Networks
- [Effective Approaches to Attention-based Neural Machine Translation](./effective-approaches-to-attention-based-neural-machine-translation.md)
- [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](./google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation.md)
- [TensorFlow - Large-Scale Machine Learning on Heterogeneous Distributed Systems](./tensorflow-large-scale-machine-learning-on-heterogeneous-distributed-systems.md)
- Generative Image Modeling Using Spatial LSTMs
- Ensemble Learning for Multi-Source Neural Machine Translation
- [Deep Speech 2 - End-to-End Speech Recognition in English and Mandarin](./deep-speech-2-end-to-end-speech-recognition-in-english-and-mandarin.md)
- [Long Short-Term Memory](./long-short-term-memory.md)
- [Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](./adaptive-subgradient-methods-for-online-learning-and-stochastic-optimization.md)
- [Recurrent Neural Network Regularization](./recurrent-neural-network-regularization.md)
- [Neural Machine Translation by Jointly Learning to Align and Translate](./neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
- Adaptive Mixtures of Local Experts
- Infinite Mixtures of Gaussian Process Experts
- A Parallel Mixture of SVMs for Very Large Scale Problems
- Memory-Efficient Backpropagation Through Time
- Improved backing-off for M-gram language modeling
- Addressing the Rare Word Problem in Neural Machine Translation
- Distributed Gaussian Processes
- Hierarchical Mixture of Classification Experts Uncovers Interactions between Brain Regions
- [Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks](./under-review-as-a-conference-paper-at-iclr-2017-delving-into-transferable-adversarial-ex-amples-and-black-box-attacks.md)
- Google's Multilingual Neural Machine Translation System - Enabling Zero-Shot Translation
- [Deep Neural Networks for Acoustic Modeling in Speech Recognition - The Shared Views of Four Research Groups](./deep-neural-networks-for-acoustic-modeling-in-speech-recognition-the-shared-views-of-four-research-groups.md)
- Hierarchical mixtures of experts and the EM algorithm
- Nonlinear Models Using Dirichlet Process Mixtures
- Mixtures of Gaussian Processes
- Edinburgh's Phrase-based Machine Translation Systems for WMT-14
- Japanese and Korean voice search
