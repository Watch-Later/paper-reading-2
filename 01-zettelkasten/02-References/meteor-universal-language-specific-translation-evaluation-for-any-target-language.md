---
title: Meteor Universal - Language Specific Translation Evaluation for Any Target Language
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# Meteor Universal - Language Specific Translation Evaluation for Any Target Language

## References

- Meteor 1.3 - Automatic Metric for Reliable Optimization and Evaluation of Machine Translation Systems
- [Moses - Open Source Toolkit for Statistical Machine Translation](./moses-open-source-toolkit-for-statistical-machine-translation.md)
- [Bleu - a Method for Automatic Evaluation of Machine Translation](./bleu-a-method-for-automatic-evaluation-of-machine-translation.md)
- Findings of the 2012 Workshop on Statistical Machine Translation
- Paraphrasing with Bilingual Parallel Corpora
- SPEDE - Probabilistic Edit Distance Metrics for MT Evaluation
- [Statistical Phrase-Based Translation](./statistical-phrase-based-translation.md)
- Findings of the 2011 Workshop on Statistical Machine Translation
- Fluency, Adequacy, or HTER? Exploring Different Human Judgments with a Tunable MT Metric
- TESLA at WMT 2011 - Translation Evaluation and Tunable Metric
- Improving AMBER, an MT Evaluation Metric
- Results of the WMT13 Metrics Shared Task
- Results of the WMT14 Metrics Shared Task
- Snowball - A language for stemming algorithms
