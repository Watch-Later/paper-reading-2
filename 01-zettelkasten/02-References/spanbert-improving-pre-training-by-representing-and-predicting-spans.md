---
title: SpanBERT - Improving Pre-training by Representing and Predicting Spans
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# SpanBERT - Improving Pre-training by Representing and Predicting Spans

## References

- End-to-end Neural Coreference Resolution
- Learning Recurrent Span Representations for Extractive Question Answering
- BERT for Coreference Resolution - Baselines and Analysis
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- ERNIE - Enhanced Language Representation with Informative Entities
- Matching the Blanks - Distributional Similarity for Relation Learning
- [Unified Language Model Pre-training for Natural Language Understanding and Generation](./unified-language-model-pre-training-for-natural-language-understanding-and-generation.md)
- [MASS - Masked Sequence to Sequence Pre-training for Language Generation](./mass-masked-sequence-to-sequence-pre-training-for-language-generation.md)
- CoNLL-2012 Shared Task - Modeling Multilingual Unrestricted Coreference in OntoNotes
- [Transformer-XL - Attentive Language Models beyond a Fixed-Length Context](./transformer-xl-attentive-language-models-beyond-a-fixed-length-context.md)
- [GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](./glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding.md)
- [RoBERTa - A Robustly Optimized BERT Pretraining Approach](./roberta-a-robustly-optimized-bert-pretraining-approach.md)
- Higher-Order Coreference Resolution with Coarse-to-Fine Inference
- [Skip-Thought Vectors](./skip-thought-vectors.md)
- [SQuAD - 100,000+ Questions for Machine Comprehension of Text](./squad-100-000-questions-for-machine-comprehension-of-text.md)
- Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling
- [Cross-lingual Language Model Pretraining](./cross-lingual-language-model-pretraining.md)
- [XLNet - Generalized Autoregressive Pretraining for Language Understanding](./xlnet-generalized-autoregressive-pretraining-for-language-understanding.md)
- [TriviaQA - A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension](./triviaqa-a-large-scale-distantly-supervised-challenge-dataset-for-reading-comprehension.md)
- [A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference](./a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference.md)
- Position-aware Attention and Supervised Data Improve Slot Filling
- pair2vec - Compositional Word-Pair Embeddings for Cross-Sentence Inference
- [Attention is All you Need](./attention-is-all-you-need.md)
- [HuggingFace's Transformers - State-of-the-art Natural Language Processing](./huggingface-s-transformers-state-of-the-art-natural-language-processing.md)
- [Universal Language Model Fine-tuning for Text Classification](./universal-language-model-fine-tuning-for-text-classification.md)
- context2vec - Learning Generic Context Embedding with Bidirectional LSTM
- [Multi-Task Deep Neural Networks for Natural Language Understanding](./multi-task-deep-neural-networks-for-natural-language-understanding.md)
- [NewsQA - A Machine Comprehension Dataset](./newsqa-a-machine-comprehension-dataset.md)
- SearchQA - A New Q&A Dataset Augmented with Context from a Search Engine
- [Natural Questions - A Benchmark for Question Answering Research](./natural-questions-a-benchmark-for-question-answering-research.md)
- HotpotQA - A Dataset for Diverse, Explainable Multi-hop Question Answering
- [Know What You Don't Know - Unanswerable Questions for SQuAD](./know-what-you-don-t-know-unanswerable-questions-for-squad.md)
- [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](./recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank.md)
- [SemEval-2017 Task 1 - Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation](./semeval-2017-task-1-semantic-textual-similarity-multilingual-and-crosslingual-focused-evaluation.md)
- [An efficient framework for learning sentence representations](./an-efficient-framework-for-learning-sentence-representations.md)
- The Seventh PASCAL Recognizing Textual Entailment Challenge
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- KERMIT - Generative Insertion-Based Modeling for Sequences
- MRQA 2019 Shared Task - Evaluating Generalization in Reading Comprehension
- The Winograd Schema Challenge
- ERNIE - Enhanced Representation through Knowledge Integration
- Blockwise Parallel Decoding for Deep Autoregressive Models
- The Second PASCAL Recognising Textual Entailment Challenge
- [Using the Output Embedding to Improve Language Models](./using-the-output-embedding-to-improve-language-models.md)
- Automatically Constructing a Corpus of Sentential Paraphrases
- [Neural Network Acceptability Judgments](./neural-network-acceptability-judgments.md)
- The PASCAL Recognising Textual Entailment Challenge
- A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- fairseq - A Fast, Extensible Toolkit for Sequence Modeling
- [Decoupled Weight Decay Regularization](./decoupled-weight-decay-regularization.md)
- [Layer Normalization](./layer-normalization.md)
- [Gaussian Error Linear Units (GELUs)](./gaussian-error-linear-units-gelus.md)
