---
title: Grounding of Textual Phrases in Images by Reconstruction
authors:
- Anna Rohrbach
- Marcus Rohrbach
- Ronghang Hu
- Trevor Darrell
- B. Schiele
fieldsOfStudy:
- Computer Science
meta_key: grounding-of-textual-phrases-in-images-by-reconstruction
numCitedBy: 377
pdf_relpath: null
ref_count: 63
status: todo
tags:
- gen-from-ref
- paper
venue: ECCV
year: 2016
---

# Grounding of Textual Phrases in Images by Reconstruction

## References

- Weakly-Supervised Alignment of Video with Text
- [Show and tell - A neural image caption generator](./show-and-tell-a-neural-image-caption-generator.md)
- Aligning where to see and what to tell - image caption with region-based attention and scene factorization
- [Deep Visual-Semantic Alignments for Generating Image Descriptions](./deep-visual-semantic-alignments-for-generating-image-descriptions.md)
- Learning Everything about Anything - Webly-Supervised Visual Concept Learning
- Improving Image-Sentence Embeddings Using Large Weakly Annotated Photo Collections
- Flickr30k Entities - Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models
- Mind's eye - A recurrent visual representation for image caption generation
- Simultaneous Object Detection and Ranking with Weak Supervision
- Describing Videos by Exploiting Temporal Structure
- [Natural Language Object Retrieval](./natural-language-object-retrieval.md)
- [Learning Deep Structure-Preserving Image-Text Embeddings](./learning-deep-structure-preserving-image-text-embeddings.md)
- Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
- [Generation and Comprehension of Unambiguous Object Descriptions](./generation-and-comprehension-of-unambiguous-object-descriptions.md)
- What Are You Talking About? Text-to-Image Coreference
- VisKE - Visual knowledge extraction and question answering by visual verification of relation phrases
- [Aligning Books and Movies - Towards Story-Like Visual Explanations by Watching Movies and Reading Books](./aligning-books-and-movies-towards-story-like-visual-explanations-by-watching-movies-and-reading-books.md)
- [Show, Attend and Tell - Neural Image Caption Generation with Visual Attention](./show-attend-and-tell-neural-image-caption-generation-with-visual-attention.md)
- Open-vocabulary Object Retrieval
- Sentence Directed Video Object Codetection
- [Long-term recurrent convolutional networks for visual recognition and description](./long-term-recurrent-convolutional-networks-for-visual-recognition-and-description.md)
- Grounding Action Descriptions in Videos
- [Sequence to Sequence Learning with Neural Networks](./sequence-to-sequence-learning-with-neural-networks.md)
- Jointly Learning to Parse and Perceive - Connecting Natural Language to the Physical World
- Multi-fold MIL Training for Weakly Supervised Object Localization
- Conditional Random Field Autoencoders for Unsupervised Structured Prediction
- Visual Semantic Search - Retrieving Videos via Complex Textual Queries
- On learning to localize objects with minimal supervision
- Book2Movie - Aligning video scenes with book chapters
- Co-localization in Real-World Images
- [Microsoft COCO - Common Objects in Context](./microsoft-coco-common-objects-in-context.md)
- Unsupervised Object Discovery and Tracking in Video Collections
- Webly Supervised Learning of Convolutional Networks
- [Delving Deep into Rectifiers - Surpassing Human-Level Performance on ImageNet Classification](./delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification.md)
- [Neural Machine Translation by Jointly Learning to Align and Translate](./neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
- [ImageNet - A large-scale hierarchical image database](./imagenet-a-large-scale-hierarchical-image-database.md)
- Every Moment Counts - Dense Detailed Labeling of Actions in Complex Videos
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](./very-deep-convolutional-networks-for-large-scale-image-recognition.md)
- Image retrieval using scene graphs
- Grounded Language Learning from Video Described with Sentences
- ReferItGame - Referring to Objects in Photographs of Natural Scenes
- [Selective Search for Object Recognition](./selective-search-for-object-recognition.md)
- Efficient Image and Video Co-localization with Frank-Wolfe Algorithm
- A Joint Model of Language and Perception for Grounded Attribute Learning
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](./batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
- [Extracting and composing robust features with denoising autoencoders](./extracting-and-composing-robust-features-with-denoising-autoencoders.md)
- The New Data and New Challenges in Multimedia Research
- [Caffe - Convolutional Architecture for Fast Feature Embedding](./caffe-convolutional-architecture-for-fast-feature-embedding.md)
- What's Cookin'? Interpreting Cooking Videos using Text, Speech and Vision
- [Long Short-Term Memory](./long-short-term-memory.md)
- [The Pascal Visual Object Classes (VOC) Challenge](./the-pascal-visual-object-classes-voc-challenge.md)
- [From image descriptions to visual denotations - New similarity metrics for semantic inference over event descriptions](./from-image-descriptions-to-visual-denotations-new-similarity-metrics-for-semantic-inference-over-event-descriptions.md)
- [Edge Boxes - Locating Object Proposals from Edges](./edge-boxes-locating-object-proposals-from-edges.md)
- [Understanding the difficulty of training deep feedforward neural networks](./understanding-the-difficulty-of-training-deep-feedforward-neural-networks.md)
- [Fast R-CNN](./fast-r-cnn.md)
- International Conference on Computer Vision (ICCV 2017)
