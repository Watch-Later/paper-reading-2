---
title: Weight Normalization - A Simple Reparameterization to Accelerate Training of Deep Neural Networks
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# Weight Normalization - A Simple Reparameterization to Accelerate Training of Deep Neural Networks

## References

- [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](./batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
- Rectified linear neural networks with tied-scalar regularization for LVCSR
- Deep Learning Made Easier by Linear Transformations in Perceptrons
- [Layer Normalization](./layer-normalization.md)
- [Recurrent Batch Normalization](./recurrent-batch-normalization.md)
- [On the importance of initialization and momentum in deep learning](./on-the-importance-of-initialization-and-momentum-in-deep-learning.md)
- Natural Neural Networks
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- [Data-dependent Initializations of Convolutional Neural Networks](./data-dependent-initializations-of-convolutional-neural-networks.md)
- [All you need is a good init](./all-you-need-is-a-good-init.md)
- [Understanding the difficulty of training deep feedforward neural networks](./understanding-the-difficulty-of-training-deep-feedforward-neural-networks.md)
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [Deeply-Supervised Nets](./deeply-supervised-nets.md)
- Optimizing Neural Networks with Kronecker-factored Approximate Curvature
- [Network In Network](./network-in-network.md)
- [Striving for Simplicity - The All Convolutional Net](./striving-for-simplicity-the-all-convolutional-net.md)
- Deep learning via Hessian-free optimization
- [Densely Connected Convolutional Networks](./densely-connected-convolutional-networks.md)
- [Long Short-Term Memory](./long-short-term-memory.md)
- [Learning Multiple Layers of Features from Tiny Images](./learning-multiple-layers-of-features-from-tiny-images.md)
- [Auto-Encoding Variational Bayes](./auto-encoding-variational-bayes.md)
- Improved Variational Inference with Inverse Autoregressive Flow
- [Maxout Networks](./maxout-networks.md)
- [Human-level control through deep reinforcement learning](./human-level-control-through-deep-reinforcement-learning.md)
- [Stochastic Backpropagation and Approximate Inference in Deep Generative Models](./stochastic-backpropagation-and-approximate-inference-in-deep-generative-models.md)
- Neural Learning in Structured Parameter Spaces - Natural Riemannian Gradient
- [DRAW - A Recurrent Neural Network For Image Generation](./draw-a-recurrent-neural-network-for-image-generation.md)
- Scaling up Natural Gradient by Sparsely Factorizing the Inverse Fisher Matrix
- [Theano - new features and speed improvements](./theano-new-features-and-speed-improvements.md)
- The Arcade Learning Environment - An Evaluation Platform for General Agents (Extended Abstract)
- Markov Chain Monte Carlo and Variational Inference - Bridging the Gap
- Rank, Trace-Norm and Max-Norm
- Acceleration of stochastic approximation by averaging
- [Deep Learning](./deep-learning.md)
