---
title: On the importance of initialization and momentum in deep learning
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# On the importance of initialization and momentum in deep learning

## References

- [Understanding the difficulty of training deep feedforward neural networks](./understanding-the-difficulty-of-training-deep-feedforward-neural-networks.md)
- Learning Recurrent Neural Networks with Hessian-Free Optimization
- Neural Networks - Tricks of the Trade
- [Generating Text with Recurrent Neural Networks](./generating-text-with-recurrent-neural-networks.md)
- [Greedy Layer-Wise Training of Deep Networks](./greedy-layer-wise-training-of-deep-networks.md)
- Deep Learning Made Easier by Linear Transformations in Perceptrons
- Training Deep and Recurrent Networks with Hessian-Free Optimization
- Learning long-term dependencies with gradient descent is difficult
- Stochastic dynamics of learning with momentum in neural networks
- [ImageNet classification with deep convolutional neural networks](./imagenet-classification-with-deep-convolutional-neural-networks.md)
- Dynamics and algorithms for stochastic search
- [A Fast Learning Algorithm for Deep Belief Nets](./a-fast-learning-algorithm-for-deep-belief-nets.md)
- [Long Short-Term Memory](./long-short-term-memory.md)
- Deep learning via Hessian-free optimization
- [Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition](./context-dependent-pre-trained-deep-neural-networks-for-large-vocabulary-speech-recognition.md)
- Neural Networks - Tricks of the Trade
- Sequence Transduction with Recurrent Neural Networks
- [Acoustic Modeling Using Deep Belief Networks](./acoustic-modeling-using-deep-belief-networks.md)
- Towards Faster Stochastic Gradient Search
- [Reducing the Dimensionality of Data with Neural Networks](./reducing-the-dimensionality-of-data-with-neural-networks.md)
- [Deep Neural Networks for Acoustic Modeling in Speech Recognition](./deep-neural-networks-for-acoustic-modeling-in-speech-recognition.md)
- SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS
- An optimal method for stochastic composite optimization
- Introductory Lectures on Convex Optimization - A Basic Course
- Improved Preconditioner for Hessian Free Optimization
- Better Mini-Batch Algorithms via Accelerated Gradient Methods
- Harnessing Nonlinearity - Predicting Chaotic Systems and Saving Energy in Wireless Communication
- Some methods of speeding up the convergence of iteration methods
- Large Scale Online Learning
- [Efficient BackProp](./efficient-backprop.md)
