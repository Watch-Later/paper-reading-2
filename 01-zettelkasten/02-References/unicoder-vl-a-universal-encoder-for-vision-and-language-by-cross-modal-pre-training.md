---
title: Unicoder-VL - A Universal Encoder for Vision and Language by Cross-modal Pre-training
authors:
- Gen Li
- Nan Duan
- Yuejian Fang
- Daxin Jiang
- Ming Zhou
fieldsOfStudy:
- Computer Science
meta_key: unicoder-vl-a-universal-encoder-for-vision-and-language-by-cross-modal-pre-training
numCitedBy: 382
pdf_relpath: null
ref_count: 46
status: todo
tags:
- gen-from-ref
- paper
venue: AAAI
year: 2020
---

# Unicoder-VL - A Universal Encoder for Vision and Language by Cross-modal Pre-training

## References

- Unicoder - A Universal Language Encoder by Pre-training with Multiple Cross-lingual Tasks
- [ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks](./vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks.md)
- [UNITER - Learning UNiversal Image-TExt Representations](./uniter-learning-universal-image-text-representations.md)
- [VL-BERT - Pre-training of Generic Visual-Linguistic Representations](./vl-bert-pre-training-of-generic-visual-linguistic-representations.md)
- [VideoBERT - A Joint Model for Video and Language Representation Learning](./videobert-a-joint-model-for-video-and-language-representation-learning.md)
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- Dual-Path Convolutional Image-Text Embedding
- [VisualBERT - A Simple and Performant Baseline for Vision and Language](./visualbert-a-simple-and-performant-baseline-for-vision-and-language.md)
- [Attention is All you Need](./attention-is-all-you-need.md)
- [Improving Language Understanding by Generative Pre-Training](./improving-language-understanding-by-generative-pre-training.md)
- [Cross-lingual Language Model Pretraining](./cross-lingual-language-model-pretraining.md)
- [Deep Visual-Semantic Alignments for Generating Image Descriptions](./deep-visual-semantic-alignments-for-generating-image-descriptions.md)
- [Dual-path Convolutional Image-Text Embeddings with Instance Loss](./dual-path-convolutional-image-text-embeddings-with-instance-loss.md)
- [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](./bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering.md)
- [Stacked Cross Attention for Image-Text Matching](./stacked-cross-attention-for-image-text-matching.md)
- [XLNet - Generalized Autoregressive Pretraining for Language Understanding](./xlnet-generalized-autoregressive-pretraining-for-language-understanding.md)
- Position Focused Attention Network for Image-Text Matching
- [VSE++ - Improved Visual-Semantic Embeddings](./vse-improved-visual-semantic-embeddings.md)
- Pythia-A platform for vision & language research
- [From Recognition to Cognition - Visual Commonsense Reasoning](./from-recognition-to-cognition-visual-commonsense-reasoning.md)
- [Learning Semantic Concepts and Order for Image and Sentence Matching](./learning-semantic-concepts-and-order-for-image-and-sentence-matching.md)
- [Learning Deep Structure-Preserving Image-Text Embeddings](./learning-deep-structure-preserving-image-text-embeddings.md)
- Multimodal Convolutional Neural Networks for Matching Image and Sentence
- [Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image Annotations](./visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations.md)
- [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](./google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation.md)
- [Fusion of Detected Objects in Text for Visual Question Answering](./fusion-of-detected-objects-in-text-for-visual-question-answering.md)
- [VQA - Visual Question Answering](./vqa-visual-question-answering.md)
- [VSE++ - Improving Visual-Semantic Embeddings with Hard Negatives](./vse-improving-visual-semantic-embeddings-with-hard-negatives.md)
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](./very-deep-convolutional-networks-for-large-scale-image-recognition.md)
- [Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks](./faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.md)
- [Conceptual Captions - A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning](./conceptual-captions-a-cleaned-hypernymed-image-alt-text-dataset-for-automatic-image-captioning.md)
- [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](./recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank.md)
- Knowledge Aware Semantic Concept Expansion for Image-Text Matching
- [A large annotated corpus for learning natural language inference](./a-large-annotated-corpus-for-learning-natural-language-inference.md)
- [RoBERTa - A Robustly Optimized BERT Pretraining Approach](./roberta-a-robustly-optimized-bert-pretraining-approach.md)
- [ImageNet - A large-scale hierarchical image database](./imagenet-a-large-scale-hierarchical-image-database.md)
- [SQuAD - 100,000+ Questions for Machine Comprehension of Text](./squad-100-000-questions-for-machine-comprehension-of-text.md)
- Im2Text - Describing Images Using 1 Million Captioned Photographs
- [From image descriptions to visual denotations - New similarity metrics for semantic inference over event descriptions](./from-image-descriptions-to-visual-denotations-new-similarity-metrics-for-semantic-inference-over-event-descriptions.md)
- [Microsoft COCO Captions - Data Collection and Evaluation Server](./microsoft-coco-captions-data-collection-and-evaluation-server.md)
