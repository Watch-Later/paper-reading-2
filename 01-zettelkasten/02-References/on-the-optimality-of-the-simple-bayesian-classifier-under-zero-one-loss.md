---
title: On the Optimality of the Simple Bayesian Classifier under Zero-One Loss
authors:
- Pedro M. Domingos
- M. Pazzani
fieldsOfStudy:
- Computer Science
meta_key: on-the-optimality-of-the-simple-bayesian-classifier-under-zero-one-loss
numCitedBy: 3124
pdf_relpath: null
ref_count: 59
status: todo
tags:
- gen-from-ref
- paper
venue: Machine Learning
year: 2004
---

# On the Optimality of the Simple Bayesian Classifier under Zero-One Loss

## References

- Beyond Independence - Conditions for the Optimality of the Simple Bayesian Classifier
- Bayesian Network Classifiers
- Learning Limited Dependence Bayesian Classifiers
- An Analysis of Bayesian Classiiers
- On Bias, Variance, 0/1-Loss, and the Curse-of-Dimensionality
- An Analysis of Bayesian Classifiers
- Sensitivity Analysis in Bayesian Classification Models - Multiplicative Deviations
- Searching for Dependencies in Bayesian Classifiers
- Induction of Selective Bayesian Classifiers
- Eecient Learning of Selective Bayesian Network Classiiers
- A Comparison of Induction Algorithms for Selective and non-Selective Bayesian Classifiers
- Scaling Up the Accuracy of Naive-Bayes Classifiers - A Decision-Tree Hybrid
- Estimating Continuous Distributions in Bayesian Classifiers
- Induction of Recursive Bayesian Classifiers
- The effect of assuming independence in applying Bayes' theorem to risk estimation and classification in diagnosis.
- Error rates in quadratic discrimination with constraints on the covariance matrices
- Bias, Variance , And Arcing Classifiers
- Efficient Learning of Selective Bayesian Network Classifiers
- Semi-Naive Bayesian Classifier
- Quantifying Inductive Bias - AI Learning Algorithms and Valiant's Learning Framework
- Wrappers for Performance Enhancements and Oblivious Decision Graphs.
- Supervised and Unsupervised Discretization of Continuous Features
- Bias Plus Variance Decomposition for Zero-One Loss Functions
- A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features
- [C4.5 - Programs for Machine Learning](./c4-5-programs-for-machine-learning.md)
- A framework for average case analysis of conjunctive learning algorithms
- Syskill & Webert - Identifying Interesting Web Sites
- Error-Correcting Output Coding Corrects Bias and Variance
- Bias, Variance and Prediction Error for Classification Rules
- Learning from Data - Artificial Intelligence and Statistics V
- Rule Induction with CN2 - Some Recent Improvements
- Pattern classification and scene analysis
- The CN2 Induction Algorithm
- [UCI Repository of machine learning databases](./uci-repository-of-machine-learning-databases.md)
- Discovering Patterns in EEG-Signals - Comparative Study of a Few Methods
- Improving simple Bayes
- Estimating Probabilities - A Crucial Task in Machine Learning
- Constructing Decision Trees in Noisy Domains
