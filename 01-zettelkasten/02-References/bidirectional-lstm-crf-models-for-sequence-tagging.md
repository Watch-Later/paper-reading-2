---
title: Bidirectional LSTM-CRF Models for Sequence Tagging
authors:
- Zhiheng Huang
- W. Xu
- Kai Yu
fieldsOfStudy:
- Computer Science
meta_key: bidirectional-lstm-crf-models-for-sequence-tagging
numCitedBy: 2424
pdf_relpath: null
ref_count: 39
status: todo
tags:
- gen-from-ref
- paper
venue: ArXiv
year: 2015
---

# Bidirectional LSTM-CRF Models for Sequence Tagging

## References

- Recurrent conditional random field for language understanding
- Spoken language understanding using long short-term memory neural networks
- [Framewise phoneme classification with bidirectional LSTM and other neural network architectures](./framewise-phoneme-classification-with-bidirectional-lstm-and-other-neural-network-architectures.md)
- Convolutional neural network based triangular CRF for joint intent detection and slot filling
- Modeling Latent-Dynamic in Shallow Parsing - A Latent Conditional Model with Improved Inference
- Lexicon Infused Phrase Embeddings for Named Entity Resolution
- [Long Short-Term Memory](./long-short-term-memory.md)
- Effect of Non-linear Deep Architecture in Sequence Labeling
- [Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network](./feature-rich-part-of-speech-tagging-with-a-cyclic-dependency-network.md)
- [Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling](./incorporating-non-local-information-into-information-extraction-systems-by-gibbs-sampling.md)
- [Speech recognition with deep recurrent neural networks](./speech-recognition-with-deep-recurrent-neural-networks.md)
- Shallow Parsing with Conditional Random Fields
- [Conditional Random Fields - Probabilistic Models for Segmenting and Labeling Sequence Data](./conditional-random-fields-probabilistic-models-for-segmenting-and-labeling-sequence-data.md)
- Named Entity Recognition with Long Short-Term Memory
- Voting Between Multiple Data Representations for Text Chunking
- Maximum Entropy Markov Models for Information Extraction and Segmentation
- [Natural Language Processing (Almost) from Scratch](./natural-language-processing-almost-from-scratch.md)
- [Recurrent neural network based language model](./recurrent-neural-network-based-language-model.md)
- [Distributed Representations of Words and Phrases and their Compositionality](./distributed-representations-of-words-and-phrases-and-their-compositionality.md)
- A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data
- Flexible Text Segmentation with Structured Multilabel Classification
- Guided Learning for Bidirectional Sequence Classification
- Finding Structure in Time
- Structure Regularization for Structured Prediction
- SVMTool - A general POS Tagger Generator Based on Support Vector Machines
- Strategies for training large scale neural network language models
- A Maximum Entropy Model for Part-Of-Speech Tagging
- Semi-supervised condensed nearest neighbor for part-of-speech tagging
- Named Entity Recognition with a Maximum Entropy Approach
- Named Entity Recognition through Classifier Combination
- Use of Support Vector Learning for Chunk Identification
- A guide to recurrent neural networks and backpropagation
- Chunking with Support Vector Machines
- A Tutorial on Hidden Markov Models and Selected Applications
