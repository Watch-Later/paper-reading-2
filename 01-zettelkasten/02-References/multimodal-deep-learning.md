---
title: Multimodal Deep Learning
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# Multimodal Deep Learning

## References

- Multimodal Fusion and Learning with Uncertain Features Applied to Audiovisual Speech Recognition
- Adaptive Multimodal Fusion by Uncertainty Compensation With Application to Audiovisual Speech Recognition
- Self-taught learning - transfer learning from unlabeled data
- Patch-Based Representation of Visual Speech
- [Extracting and composing robust features with denoising autoencoders](./extracting-and-composing-robust-features-with-denoising-autoencoders.md)
- Information Theoretic Feature Extraction for Audio-Visual Speech Recognition
- CUAVE - A new audio-visual database for multimodal human-computer interface research
- Sparse deep belief net model for visual area V2
- Adaptive multimodal fusion by uncertainty compensation
- See me, hear me - integrating automatic speech recognition and lip-reading
- [A Fast Learning Algorithm for Deep Belief Nets](./a-fast-learning-algorithm-for-deep-belief-nets.md)
- The challenge of multispeaker lip-reading
- Lipreading With Local Spatiotemporal Descriptors
- Extraction of Visual Features for Lipreading
- Audio-Visual Automatic Speech Recognition - An Overview
- Eigenlips for robust speech recognition
- Adaptive bimodal sensor fusion for automatic speechreading
- Integration of acoustic and visual speech signals using neural networks
- Semantic hashing
- [Reducing the Dimensionality of Data with Neural Networks](./reducing-the-dimensionality-of-data-with-neural-networks.md)
- [Histograms of oriented gradients for human detection](./histograms-of-oriented-gradients-for-human-detection.md)
- Hearing lips and seeing voices
- [Training Products of Experts by Minimizing Contrastive Divergence](./training-products-of-experts-by-minimizing-contrastive-divergence.md)
- Lipreading and audio-visual speech perception.
- Canonical Correlation Analysis - An Overview with Application to Learning Methods
- Multitask Learning
