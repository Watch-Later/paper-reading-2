---
title: Simple and Effective Multi-Paragraph Reading Comprehension
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# Simple and Effective Multi-Paragraph Reading Comprehension

## References

- Multi-Mention Learning for Reading Comprehension with Neural Cascades
- S-Net - From Answer Extraction to Answer Generation for Machine Reading Comprehension
- [Text Understanding with the Attention Sum Reader Network](./text-understanding-with-the-attention-sum-reader-network.md)
- [Bidirectional Attention Flow for Machine Comprehension](./bidirectional-attention-flow-for-machine-comprehension.md)
- [SQuAD - 100,000+ Questions for Machine Comprehension of Text](./squad-100-000-questions-for-machine-comprehension-of-text.md)
- Smarnet - Teaching Machines to Read and Comprehend Like Human
- [Machine Comprehension Using Match-LSTM and Answer Pointer](./machine-comprehension-using-match-lstm-and-answer-pointer.md)
- [Gated Self-Matching Networks for Reading Comprehension and Question Answering](./gated-self-matching-networks-for-reading-comprehension-and-question-answering.md)
- R3 - Reinforced Reader-Ranker for Open-Domain Question Answering
- Mnemonic Reader - Machine Comprehension with Iterative Aligning and Multi-hop Answer Pointing
- Reading Wikipedia to Answer Open-Domain Questions
- [TriviaQA - A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension](./triviaqa-a-large-scale-distantly-supervised-challenge-dataset-for-reading-comprehension.md)
- [Adversarial Examples for Evaluating Reading Comprehension Systems](./adversarial-examples-for-evaluating-reading-comprehension-systems.md)
- The TREC-8 Question Answering Track Report
- Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering
- Reading Twice for Natural Language Understanding
- MEMEN - Multi-layer Embedding with Memory Networks for Machine Comprehension
- [Teaching Machines to Read and Comprehend](./teaching-machines-to-read-and-comprehend.md)
- Dynamic Integration of Background Knowledge in Neural NLU Systems
- Making Neural QA as Simple as Possible but not Simpler
- Question Answering through Transfer Learning from Large Fine-grained Supervision Data
- [WikiReading - A Novel Large-scale Language Understanding Task over Wikipedia](./wikireading-a-novel-large-scale-language-understanding-task-over-wikipedia.md)
- [MS MARCO - A Human Generated MAchine Reading COmprehension Dataset](./ms-marco-a-human-generated-machine-reading-comprehension-dataset.md)
- YodaQA - A Modular Question Answering System Pipeline
- FastQA - A Simple and Efficient Neural Architecture for Question Answering
- Quasar - Datasets for Question Answering by Search and Reading
- [Semantic Parsing on Freebase from Question-Answer Pairs](./semantic-parsing-on-freebase-from-question-answer-pairs.md)
- [The Goldilocks Principle - Reading Children's Books with Explicit Memory Representations](./the-goldilocks-principle-reading-children-s-books-with-explicit-memory-representations.md)
- [Long Short-Term Memory-Networks for Machine Reading](./long-short-term-memory-networks-for-machine-reading.md)
- TAGME - on-the-fly annotation of short text fragments (by wikipedia entities)
- [GloVe - Global Vectors for Word Representation](./glove-global-vectors-for-word-representation.md)
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](./learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation.md)
- [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](./a-theoretically-grounded-application-of-dropout-in-recurrent-neural-networks.md)
- [ADADELTA - An Adaptive Learning Rate Method](./adadelta-an-adaptive-learning-rate-method.md)
