---
title: Hogwild - A Lock-Free Approach to Parallelizing Stochastic Gradient Descent
authors:
- B. Recht
- "Christopher R\xE9"
- Stephen J. Wright
- Feng Niu
fieldsOfStudy:
- Computer Science
meta_key: hogwild-a-lock-free-approach-to-parallelizing-stochastic-gradient-descent
numCitedBy: 2018
pdf_relpath: null
ref_count: 32
status: todo
tags:
- gen-from-ref
- paper
venue: NIPS
year: 2011
---

# Hogwild - A Lock-Free Approach to Parallelizing Stochastic Gradient Descent

## References

- Parallelized Stochastic Gradient Descent
- The Landscape of Parallel Computing Research - A View from Berkeley
- Optimal Distributed Online Prediction Using Mini-Batches
- Parallel stochastic gradient algorithms for large-scale matrix completion
- Parallel and Distributed Computation - Numerical Methods
- An Incremental Gradient(-Projection) Method with Momentum Term and Adaptive Stepsize Rule
- Analysis of an approximate gradient projection method with applications to the backpropagation algorithm
- MapReduce - simplified data processing on large clusters
- Convergence Rate of Incremental Subgradient Algorithms
- Distributed Dual Averaging In Networks
- Sparse Online Learning via Truncated Gradient
- Practical Large-Scale Optimization for Max-norm Regularization
- [An experimental comparison of min-cut/max- flow algorithms for energy minimization in vision](./an-experimental-comparison-of-min-cut-max-flow-algorithms-for-energy-minimization-in-vision.md)
- Robust Stochastic Approximation Approach to Stochastic Programming
- Training linear SVMs in linear time
- Slow Learners are Fast
- Distributed Asynchronous Deterministic and Stochastic Gradient Optimization Algorithms
- Exact matrix completion via convex optimization
- The Tradeoffs of Large Scale Learning
- Guaranteed Minimum-Rank Solutions of Linear Matrix Equations via Nuclear Norm Minimization
- RCV1 - A New Benchmark Collection for Text Categorization Research
- An improved approximation algorithm for multiway cut
- Web Scale Entity Resolution using Relational Evidence
- SVM optimization - inverse dependence on training set size
- Editors
- Maximum-Margin Matrix Factorization
- NONLINEAR PROGRAMMING
- Dremel - Interactive Analysis of Web-Scale Datasets
