---
title: Random Search for Hyper-Parameter Optimization
authors:
- J. Bergstra
- Yoshua Bengio
fieldsOfStudy:
- Computer Science
meta_key: random-search-for-hyper-parameter-optimization
numCitedBy: 5672
pdf_relpath: null
ref_count: 39
status: todo
tags:
- gen-from-ref
- paper
venue: J. Mach. Learn. Res.
year: 2012
---

# Random Search for Hyper-Parameter Optimization

## References

- Automated configuration of algorithms for solving hard computational problems
- Random search for hyper-parameter optimization
- Sequential Model-Based Optimization for General Algorithm Configuration
- Simulation-Based Optimization with Stochastic Approximation Using Common Random Numbers
- Choosing search heuristics by non-stationary reinforcement learning
- A Direct Search Optimization Method That Models the Objective and Constraint Functions by Linear Interpolation
- Quas-Monte Carlo Strategies for Stochastic Optimization
- Reducing the Time Complexity of the Derandomized Evolution Strategy with Covariance Matrix Adaptation (CMA-ES)
- [A Fast Learning Algorithm for Deep Belief Nets](./a-fast-learning-algorithm-for-deep-belief-nets.md)
- [Gaussian Processes for Machine Learning](./gaussian-processes-for-machine-learning.md)
- [Understanding the difficulty of training deep feedforward neural networks](./understanding-the-difficulty-of-training-deep-feedforward-neural-networks.md)
- Parameter Screening and Optimisation for ILP using Designed Experiments
- Response Surface Methodology for Optimizing Hyper Parameters
- On the efficiency of certain quasi-random sequences of points in evaluating multi-dimensional integrals
- A Simplex Method for Function Minimization
- [Learning Deep Architectures for AI](./learning-deep-architectures-for-ai.md)
- [Optimization by Simulated Annealing](./optimization-by-simulated-annealing.md)
- Assessing Relevance determination methods using DELVE
- Why Does Unsupervised Pre-training Help Deep Learning?
- [Neural Networks for Pattern Recognition](./neural-networks-for-pattern-recognition.md)
- [A Practical Guide to Training Restricted Boltzmann Machines](./a-practical-guide-to-training-restricted-boltzmann-machines.md)
- [Gradient-based learning applied to document recognition](./gradient-based-learning-applied-to-document-recognition.md)
- A Comparison of Three Methods for Selecting Values of Input Variables in the Analysis of Output From a Computer Code
- An empirical evaluation of deep architectures on problems with many factors of variation
- Implementation and tests of low-discrepancy sequences
- GNU Scientific Library Reference Manual - Third Edition
- [LIBSVM - A library for support vector machines](./libsvm-a-library-for-support-vector-machines.md)
- [Extracting and composing robust features with denoising autoencoders](./extracting-and-composing-robust-features-with-denoising-autoencoders.md)
- An economic method of computing LPτ-sequences
- Adaptive Control Processes - A Guided Tour.
- Global Optimization Algorithms -- Theory and Application
- [Efficient BackProp](./efficient-backprop.md)
- Valuation of mortgage-backed securities using Brownian bridges to reduce effective dimension
- Rechenberg, Ingo, Evolutionsstrategie - Optimierung technischer Systeme nach Prinzipien der biologischen Evolution. 170 S. mit 36 Abb. Frommann‐Holzboog‐Verlag. Stuttgart 1973. Broschiert
- Evolutionsstrategie - Optimierung technischer Systeme nach Prinzipien der biologischen Evolution
