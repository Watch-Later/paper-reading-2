---
title: HuggingFace's Transformers - State-of-the-art Natural Language Processing
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# HuggingFace's Transformers - State-of-the-art Natural Language Processing

## References

- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- [AllenNLP - A Deep Semantic Natural Language Processing Platform](./allennlp-a-deep-semantic-natural-language-processing-platform.md)
- Reformer - The Efficient Transformer
- [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](./exploring-the-limits-of-transfer-learning-with-a-unified-text-to-text-transformer.md)
- [DistilBERT, a distilled version of BERT - smaller, faster, cheaper and lighter](./distilbert-a-distilled-version-of-bert-smaller-faster-cheaper-and-lighter.md)
- [ALBERT - A Lite BERT for Self-supervised Learning of Language Representations](./albert-a-lite-bert-for-self-supervised-learning-of-language-representations.md)
- [SuperGLUE - A Stickier Benchmark for General-Purpose Language Understanding Systems](./superglue-a-stickier-benchmark-for-general-purpose-language-understanding-systems.md)
- [Transformer-XL - Attentive Language Models beyond a Fixed-Length Context](./transformer-xl-attentive-language-models-beyond-a-fixed-length-context.md)
- exBERT - A Visual Analysis Tool to Explore Learned Representations in Transformer Models
- Transfer Learning in Natural Language Processing
- FLAIR - An Easy-to-Use Framework for State-of-the-Art NLP
- [GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](./glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding.md)
- [XLNet - Generalized Autoregressive Pretraining for Language Understanding](./xlnet-generalized-autoregressive-pretraining-for-language-understanding.md)
- [Language Models are Unsupervised Multitask Learners](./language-models-are-unsupervised-multitask-learners.md)
- Large-Scale Transfer Learning for Natural Language Generation
- [Attention is All you Need](./attention-is-all-you-need.md)
- Longformer - The Long-Document Transformer
- Megatron-LM - Training Multi-Billion Parameter Language Models Using Model Parallelism
- Stanza - A Python Natural Language Processing Toolkit for Many Human Languages
- [BART - Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](./bart-denoising-sequence-to-sequence-pre-training-for-natural-language-generation-translation-and-comprehension.md)
- [Improving Language Understanding by Generative Pre-Training](./improving-language-understanding-by-generative-pre-training.md)
- [SciBERT - A Pretrained Language Model for Scientific Text](./scibert-a-pretrained-language-model-for-scientific-text.md)
- FlauBERT - Unsupervised Language Model Pre-training for French
- [Universal Language Model Fine-tuning for Text Classification](./universal-language-model-fine-tuning-for-text-classification.md)
- [Cross-lingual Language Model Pretraining](./cross-lingual-language-model-pretraining.md)
- jiant - A Software Toolkit for Research on General-Purpose Text Understanding Models
- TransferTransfo - A Transfer Learning Approach for Neural Network Based Conversational Agents
- Are Sixteen Heads Really Better than One?
- BERT Rediscovers the Classical NLP Pipeline
- COMET - Commonsense Transformers for Automatic Knowledge Graph Construction
- BoolQ - Exploring the Surprising Difficulty of Natural Yes/No Questions
- [RoBERTa - A Robustly Optimized BERT Pretraining Approach](./roberta-a-robustly-optimized-bert-pretraining-approach.md)
- What Does BERT Look at? An Analysis of BERT's Attention
- [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](./recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank.md)
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- Pooled Contextualized Embeddings for Named Entity Recognition
- [SpanBERT - Improving Pre-training by Representing and Predicting Spans](./spanbert-improving-pre-training-by-representing-and-predicting-spans.md)
- [Contextual String Embeddings for Sequence Labeling](./contextual-string-embeddings-for-sequence-labeling.md)
- [Learned in Translation - Contextualized Word Vectors](./learned-in-translation-contextualized-word-vectors.md)
- WiC - the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations
- [A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference](./a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference.md)
- [Automatic differentiation in PyTorch](./automatic-differentiation-in-pytorch.md)
- fairseq - A Fast, Extensible Toolkit for Sequence Modeling
- Looking Beyond the Surface - A Challenge Set for Reading Comprehension over Multiple Sentences
- [SQuAD - 100,000+ Questions for Machine Comprehension of Text](./squad-100-000-questions-for-machine-comprehension-of-text.md)
- LSTMVis - A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks
- Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation
- SWAG - A Large-Scale Adversarial Dataset for Grounded Commonsense Inference
- Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge
- [The Stanford CoreNLP Natural Language Processing Toolkit](./the-stanford-corenlp-natural-language-processing-toolkit.md)
- The Curious Case of Neural Text Degeneration
- [OpenNMT - Open-Source Toolkit for Neural Machine Translation](./opennmt-open-source-toolkit-for-neural-machine-translation.md)
- The Sixth PASCAL Recognizing Textual Entailment Challenge
- TVM - An Automated End-to-End Optimizing Compiler for Deep Learning
- The Seventh PASCAL Recognizing Textual Entailment Challenge
- The Second PASCAL Recognising Textual Entailment Challenge
- Automatically Constructing a Corpus of Sentential Paraphrases
- [Neural Network Acceptability Judgments](./neural-network-acceptability-judgments.md)
- [RACE - Large-scale ReAding Comprehension Dataset From Examinations](./race-large-scale-reading-comprehension-dataset-from-examinations.md)
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- [Know What You Don't Know - Unanswerable Questions for SQuAD](./know-what-you-don-t-know-unanswerable-questions-for-squad.md)
- [NLTK - The Natural Language Toolkit](./nltk-the-natural-language-toolkit.md)
- Fixing Weight Decay Regularization in Adam
- [Decoupled Weight Decay Regularization](./decoupled-weight-decay-regularization.md)
- ReCoRD - Bridging the Gap between Human and Machine Commonsense Reading Comprehension
- Supervised Multimodal Bitransformers for Classifying Images and Text
- The Winograd Schema Challenge
- Tensor2Tensor for Neural Machine Translation
- SemEval-2012 Task 7 - Choice of Plausible Alternatives - An Evaluation of Commonsense Causal Reasoning
- Model Cards for Model Reporting
- Gender Bias in Coreference Resolution
- The Third PASCAL Recognizing Textual Entailment Challenge
- Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment
