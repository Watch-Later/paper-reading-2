---
title: Using the Output Embedding to Improve Language Models
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# Using the Output Embedding to Improve Language Models

## References

- Tying Word Vectors and Word Classifiers - A Loss Framework for Language Modeling
- [LSTM Neural Networks for Language Modeling](./lstm-neural-networks-for-language-modeling.md)
- word2vec Explained - deriving Mikolov et al.'s negative-sampling word-embedding method
- Learning word embeddings efficiently with noise-contrastive estimation
- [Recurrent Continuous Translation Models](./recurrent-continuous-translation-models.md)
- Gated Word-Character Recurrent Language Model
- A Scalable Hierarchical Distributed Language Model
- A fast and simple algorithm for training neural probabilistic language models
- [Sequence to Sequence Learning with Neural Networks](./sequence-to-sequence-learning-with-neural-networks.md)
- A Dual Embedding Space Model for Document Ranking
- [Recurrent neural network based language model](./recurrent-neural-network-based-language-model.md)
- [Efficient Estimation of Word Representations in Vector Space](./efficient-estimation-of-word-representations-in-vector-space.md)
- [Extensions of recurrent neural network language model](./extensions-of-recurrent-neural-network-language-model.md)
- A Fixed-Size Encoding Method for Variable-Length Sequences with its Application to Neural Network Language Models
- Neural Architecture Search with Reinforcement Learning
- Better Word Representations with Recursive Neural Networks for Morphology
- Recurrent Highway Networks
- Edinburgh Neural Machine Translation Systems for WMT 16
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](./learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation.md)
- [Neural Machine Translation of Rare Words with Subword Units](./neural-machine-translation-of-rare-words-with-subword-units.md)
- [Neural Machine Translation by Jointly Learning to Align and Translate](./neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
- [Recurrent Neural Network Regularization](./recurrent-neural-network-regularization.md)
- [Distributed Representations of Words and Phrases and their Compositionality](./distributed-representations-of-words-and-phrases-and-their-compositionality.md)
- Domain Adaptation via Pseudo In-Domain Data Selection
- A Neural Probabilistic Language Model
- Learning Longer Memory in Recurrent Neural Networks
- [Learning Word Vectors for Sentiment Analysis](./learning-word-vectors-for-sentiment-analysis.md)
- [Distilling the Knowledge in a Neural Network](./distilling-the-knowledge-in-a-neural-network.md)
- How to Construct Deep Recurrent Neural Networks
- [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](./a-theoretically-grounded-application-of-dropout-in-recurrent-neural-networks.md)
- Large-scale learning of word relatedness with constraints
- Achieving Human Parity in Conversational Speech Recognition
- Building a Large Annotated Corpus of English - The Penn Treebank
- Improving Neural Networks with Dropout
- [Generating Sequences With Recurrent Neural Networks](./generating-sequences-with-recurrent-neural-networks.md)
- An Unsupervised Model for Instance Level Subcategorization Acquisition
- Multimodal Distributional Semantics
- [Long Short-Term Memory](./long-short-term-memory.md)
- [SimLex-999 - Evaluating Semantic Models With (Genuine) Similarity Estimation](./simlex-999-evaluating-semantic-models-with-genuine-similarity-estimation.md)
- Noisy Activation Functions
- Practical solutions to the problem of diagonal dominance in kernel document clustering
- Dropout as a Bayesian Approximation - Representing Model Uncertainty in Deep Learning
- [ADADELTA - An Adaptive Learning Rate Method](./adadelta-an-adaptive-learning-rate-method.md)
- A new algorithm for data compression
- A New Algorithm For Data Compression
