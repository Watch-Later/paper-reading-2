---
title: Learning Video Representations using Contrastive Bidirectional Transformer
authors:
- Chen Sun
- Fabien Baradel
- K. Murphy
- C. Schmid
fieldsOfStudy:
- Computer Science
meta_key: learning-video-representations-using-contrastive-bidirectional-transformer
numCitedBy: 170
pdf_relpath: null
ref_count: 65
status: todo
tags:
- gen-from-ref
- paper
venue: ''
year: 2019
---

# Learning Video Representations using Contrastive Bidirectional Transformer

## References

- NeuralNetwork-Viterbi - A Framework for Weakly Supervised Video Learning
- [VideoBERT - A Joint Model for Video and Language Representation Learning](./videobert-a-joint-model-for-video-and-language-representation-learning.md)
- [Shuffle and Learn - Unsupervised Learning Using Temporal Order Verification](./shuffle-and-learn-unsupervised-learning-using-temporal-order-verification.md)
- Data-Efficient Image Recognition with Contrastive Predictive Coding
- Video Representation Learning by Dense Predictive Coding
- Self-Supervised Spatiotemporal Feature Learning via Video Rotation Prediction.
- Self-Supervised Spatiotemporal Learning via Video Clip Order Prediction
- Unsupervised Representation Learning by Sorting Sequences
- Long-Term Feature Banks for Detailed Video Understanding
- [Two-Stream Convolutional Networks for Action Recognition in Videos](./two-stream-convolutional-networks-for-action-recognition-in-videos.md)
- [Generating Videos with Scene Dynamics](./generating-videos-with-scene-dynamics.md)
- The Sound of Pixels
- SoundNet - Learning Sound Representations from Unlabeled Video
- Learning a Text-Video Embedding from Incomplete and Heterogeneous Data
- A Structured Model for Action Detection
- Tracking Emerges by Colorizing Videos
- Representation Learning with Contrastive Predictive Coding
- Weakly-Supervised Action Segmentation with Iterative Soft Boundary Assignment
- C3D - Generic Features for Video Analysis
- [End-to-End Dense Video Captioning with Masked Transformer](./end-to-end-dense-video-captioning-with-masked-transformer.md)
- Self-Supervised Spatio-Temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics
- Unsupervised Learning of Visual Representations Using Videos
- Long-Term Temporal Convolutions for Action Recognition
- HowTo100M - Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips
- Anticipating Visual Representations from Unlabeled Video
- Rethinking Spatiotemporal Feature Learning For Video Understanding
- Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset
- Temporal Cycle-Consistency Learning
- Learning Correspondence From the Cycle-Consistency of Time
- Weakly-Supervised Video Object Grounding from Text by Loss Weighting and Object Interaction
- Unsupervised Learning from Narrated Instruction Videos
- [Unicoder-VL - A Universal Encoder for Vision and Language by Cross-modal Pre-training](./unicoder-vl-a-universal-encoder-for-vision-and-language-by-cross-modal-pre-training.md)
- Learning deep representations by mutual information estimation and maximization
- Relational Action Forecasting
- [Learning Spatiotemporal Features with 3D Convolutional Networks](./learning-spatiotemporal-features-with-3d-convolutional-networks.md)
- [Ambient Sound Provides Supervision for Visual Learning](./ambient-sound-provides-supervision-for-visual-learning.md)
- Patch to the Future - Unsupervised Visual Prediction
- [VisualBERT - A Simple and Performant Baseline for Vision and Language](./visualbert-a-simple-and-performant-baseline-for-vision-and-language.md)
- When will you do what? - Anticipating Temporal Occurrences of Activities
- [UCF101 - A Dataset of 101 Human Actions Classes From Videos in The Wild](./ucf101-a-dataset-of-101-human-actions-classes-from-videos-in-the-wild.md)
- [LXMERT - Learning Cross-Modality Encoder Representations from Transformers](./lxmert-learning-cross-modality-encoder-representations-from-transformers.md)
- [ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks](./vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks.md)
- [HMDB - A large video database for human motion recognition](./hmdb-a-large-video-database-for-human-motion-recognition.md)
- Contrastive Multiview Coding
- [Attention is All you Need](./attention-is-all-you-need.md)
- The Kinetics Human Action Video Dataset
- ActivityNet - A large-scale video benchmark for human activity understanding
- COIN - A Large-Scale Dataset for Comprehensive Instructional Video Analysis
- Towards Automatic Learning of Procedures From Web Instructional Videos
- [Aligning Books and Movies - Towards Story-Like Visual Explanations by Watching Movies and Reading Books](./aligning-books-and-movies-towards-story-like-visual-explanations-by-watching-movies-and-reading-books.md)
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- AVA - A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions
- [VL-BERT - Pre-training of Generic Visual-Linguistic Representations](./vl-bert-pre-training-of-generic-visual-linguistic-representations.md)
- Leveraging the Present to Anticipate the Future in Videos
- MovieGraphs - Towards Understanding Human-Centric Situations from Videos
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- [Visually Indicated Sounds](./visually-indicated-sounds.md)
- The Language of Actions - Recovering the Syntax and Semantics of Goal-Directed Human Activities
- Noise-contrastive estimation - A new estimation principle for unnormalized statistical models
- [Exploring the Limits of Language Modeling](./exploring-the-limits-of-language-modeling.md)
- Combining embedded accelerometers with computer vision for recognizing food preparation activities
- [Long Short-Term Memory](./long-short-term-memory.md)
- MINE - Mutual Information Neural Estimation
- On Variational Bounds of Mutual Information
- [BERT has a Mouth, and It Must Speak - BERT as a Markov Random Field Language Model](./bert-has-a-mouth-and-it-must-speak-bert-as-a-markov-random-field-language-model.md)
