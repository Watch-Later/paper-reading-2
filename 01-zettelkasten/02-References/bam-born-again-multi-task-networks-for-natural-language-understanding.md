---
title: BAM! Born-Again Multi-Task Networks for Natural Language Understanding
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# BAM! Born-Again Multi-Task Networks for Natural Language Understanding

## References

- [A Joint Many-Task Model - Growing a Neural Network for Multiple NLP Tasks](./a-joint-many-task-model-growing-a-neural-network-for-multiple-nlp-tasks.md)
- Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding
- [Multi-Task Deep Neural Networks for Natural Language Understanding](./multi-task-deep-neural-networks-for-natural-language-understanding.md)
- Identifying beneficial task relations for multi-task learning in deep neural networks
- Latent Multi-Task Architecture Learning
- A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks
- [Deep multi-task learning with low level tasks supervised at lower layers](./deep-multi-task-learning-with-low-level-tasks-supervised-at-lower-layers.md)
- [A unified architecture for natural language processing - deep neural networks with multitask learning](./a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning.md)
- Can You Tell Me How to Get Past Sesame Street? Sentence-Level Pretraining Beyond Language Modeling
- [An Overview of Multi-Task Learning in Deep Neural Networks](./an-overview-of-multi-task-learning-in-deep-neural-networks.md)
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- [Multi-task Sequence to Sequence Learning](./multi-task-sequence-to-sequence-learning.md)
- [GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](./glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding.md)
- Distilling Word Embeddings - An Encoding Approach
- Looking for ELMo's friends - Sentence-Level Pretraining Beyond Language Modeling
- [Sentence Encoders on STILTs - Supplementary Training on Intermediate Labeled-data Tasks](./sentence-encoders-on-stilts-supplementary-training-on-intermediate-labeled-data-tasks.md)
- [Attention is All you Need](./attention-is-all-you-need.md)
- Distral - Robust multitask reinforcement learning
- [Universal Language Model Fine-tuning for Text Classification](./universal-language-model-fine-tuning-for-text-classification.md)
- [Actor-Mimic - Deep Multitask and Transfer Reinforcement Learning](./actor-mimic-deep-multitask-and-transfer-reinforcement-learning.md)
- When is multitask learning effective? Semantic sequence prediction under varying data conditions
- Born Again Neural Networks
- Semi-supervised Sequence Learning
- Multilingual Neural Machine Translation with Knowledge Distillation
- [Distilling the Knowledge in a Neural Network](./distilling-the-knowledge-in-a-neural-network.md)
- Multitask Learning
- Unifying Question Answering and Text Classification via Span Extraction
- Adversarial Multi-task Learning for Text Classification
- Unifying Question Answering, Text Classification, and Regression via Span Extraction
- [SQuAD - 100,000+ Questions for Machine Comprehension of Text](./squad-100-000-questions-for-machine-comprehension-of-text.md)
- [A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference](./a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference.md)
- [Deep Contextualized Word Representations](./deep-contextualized-word-representations.md)
- [SemEval-2017 Task 1 - Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation](./semeval-2017-task-1-semantic-textual-similarity-multilingual-and-crosslingual-focused-evaluation.md)
- Distilling an Ensemble of Greedy Dependency Parsers into One MST Parser
- [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](./recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank.md)
- [Neural Machine Translation of Rare Words with Subword Units](./neural-machine-translation-of-rare-words-with-subword-units.md)
- [Neural Network Acceptability Judgments](./neural-network-acceptability-judgments.md)
- Do Deep Nets Really Need to be Deep?
- Model compression
- [The Natural Language Decathlon - Multitask Learning as Question Answering](./the-natural-language-decathlon-multitask-learning-as-question-answering.md)
- Automatically Constructing a Corpus of Sentential Paraphrases
- A Simple Sequentially Rejective Multiple Test Procedure
- The Third PASCAL Recognizing Textual Entailment Challenge
