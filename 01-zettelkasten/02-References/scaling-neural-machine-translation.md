---
title: Scaling Neural Machine Translation
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# Scaling Neural Machine Translation

## References

- Weighted Transformer Network for Machine Translation
- Large Scale Language Modeling - Converging on 40GB of Text in Four Hours
- [Attention is All you Need](./attention-is-all-you-need.md)
- [Convolutional Sequence to Sequence Learning](./convolutional-sequence-to-sequence-learning.md)
- The Best of Both Worlds - Combining Recent Advances in Neural Machine Translation
- Analyzing Uncertainty in Neural Machine Translation
- [Accurate, Large Minibatch SGD - Training ImageNet in 1 Hour](./accurate-large-minibatch-sgd-training-imagenet-in-1-hour.md)
- [Neural Machine Translation by Jointly Learning to Align and Translate](./neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
- [Neural Machine Translation of Rare Words with Subword Units](./neural-machine-translation-of-rare-words-with-subword-units.md)
- Mixed Precision Training
- Pieces of Eight - 8-bit Neural Machine Translation
- [Rethinking the Inception Architecture for Computer Vision](./rethinking-the-inception-architecture-for-computer-vision.md)
- [A Deep Reinforced Model for Abstractive Summarization](./a-deep-reinforced-model-for-abstractive-summarization.md)
- Don't Decay the Learning Rate, Increase the Batch Size
- [Self-Attention with Relative Position Representations](./self-attention-with-relative-position-representations.md)
- [Get To The Point - Summarization with Pointer-Generator Networks](./get-to-the-point-summarization-with-pointer-generator-networks.md)
- High-Accuracy Low-Precision Training
- Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings
- Train longer, generalize better - closing the generalization gap in large batch training of neural networks
- Training deep neural networks with low precision multiplications
- Deep learning with COTS HPC systems
- [Layer Normalization](./layer-normalization.md)
- [Large Scale Distributed Deep Networks](./large-scale-distributed-deep-networks.md)
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- Regularizing Neural Networks by Penalizing Confident Output Distributions
- A Call for Clarity in Reporting BLEU Scores
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [Dropout - a simple way to prevent neural networks from overfitting](./dropout-a-simple-way-to-prevent-neural-networks-from-overfitting.md)
- Revisiting Distributed Synchronous SGD
- Zipporah - a Fast and Scalable Data Cleaning System for Noisy Web-Crawled Parallel Corpora
- A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues
- [Moses - Open Source Toolkit for Statistical Machine Translation](./moses-open-source-toolkit-for-statistical-machine-translation.md)
- Communication-Computation Efficient Gradient Coding
- Backpropagation without Multiplication
- A Neural Network Approach to Context-Sensitive Generation of Conversational Responses
- Gradient Coding - Avoiding Stragglers in Distributed Learning
