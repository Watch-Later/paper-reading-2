---
title: LSTM Neural Networks for Language Modeling
authors:
- M. Sundermeyer
- "R. Schl\xFCter"
- H. Ney
fieldsOfStudy:
- Computer Science
meta_key: lstm-neural-networks-for-language-modeling
numCitedBy: 1491
pdf_relpath: null
ref_count: 18
status: todo
tags:
- gen-from-ref
- paper
venue: INTERSPEECH
year: 2012
---

# LSTM Neural Networks for Language Modeling

## References

- [Recurrent neural network based language model](./recurrent-neural-network-based-language-model.md)
- Performance analysis of Neural Networks in combination with n-gram language models
- Hierarchical Probabilistic Neural Network Language Model
- [Extensions of recurrent neural network language model](./extensions-of-recurrent-neural-network-language-model.md)
- Training Continuous Space Language Models - Some Practical Issues
- Continuous space language models
- [Framewise phoneme classification with bidirectional LSTM and other neural network architectures](./framewise-phoneme-classification-with-bidirectional-lstm-and-other-neural-network-architectures.md)
- RNNLM - Recurrent Neural Network Language Modeling Toolkit
- Learning long-term dependencies with gradient descent is difficult
- A Neural Probabilistic Language Model
- Learning Precise Timing with LSTM Recurrent Networks
- Learning Recurrent Neural Networks with Hessian-Free Optimization
- Classes for fast maximum entropy training
- [Long Short-Term Memory](./long-short-term-memory.md)
- Learning representations by back-propagating errors
- Improved backing-off for M-gram language modeling
- Finding Structure in Time
- Neural networks for pattern recognition
