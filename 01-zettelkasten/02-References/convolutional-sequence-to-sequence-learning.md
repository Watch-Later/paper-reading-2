---
title: Convolutional Sequence to Sequence Learning
pdf_relpath: null
status: todo
tags:
- gen-from-ref
- paper
---

# Convolutional Sequence to Sequence Learning

## References

- [Sequence to Sequence Learning with Neural Networks](./sequence-to-sequence-learning-with-neural-networks.md)
- A Convolutional Encoder Model for Neural Machine Translation
- [Language Modeling with Gated Convolutional Networks](./language-modeling-with-gated-convolutional-networks.md)
- Encoding Source Language with Convolutional Neural Network for Machine Translation
- Quasi-Recurrent Neural Networks
- [End-To-End Memory Networks](./end-to-end-memory-networks.md)
- [Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation](./deep-recurrent-models-with-fast-forward-connections-for-neural-machine-translation.md)
- [Pixel Recurrent Neural Networks](./pixel-recurrent-neural-networks.md)
- [Weight Normalization - A Simple Reparameterization to Accelerate Training of Deep Neural Networks](./weight-normalization-a-simple-reparameterization-to-accelerate-training-of-deep-neural-networks.md)
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](./learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation.md)
- [Outrageously Large Neural Networks - The Sparsely-Gated Mixture-of-Experts Layer](./outrageously-large-neural-networks-the-sparsely-gated-mixture-of-experts-layer.md)
- [Conditional Image Generation with PixelCNN Decoders](./conditional-image-generation-with-pixelcnn-decoders.md)
- [Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond](./abstractive-text-summarization-using-sequence-to-sequence-rnns-and-beyond.md)
- [On the importance of initialization and momentum in deep learning](./on-the-importance-of-initialization-and-momentum-in-deep-learning.md)
- Neural Headline Generation with Sentence-wise Optimization
- Neural Machine Translation with Recurrent Attention Modeling
- Montreal Neural Machine Translation Systems for WMT'15
- [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](./batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
- [On the difficulty of training recurrent neural networks](./on-the-difficulty-of-training-recurrent-neural-networks.md)
- [Attention-Based Models for Speech Recognition](./attention-based-models-for-speech-recognition.md)
- [Neural Machine Translation by Jointly Learning to Align and Translate](./neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [Google's Neural Machine Translation System - Bridging the Gap between Human and Machine Translation](./google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation.md)
- Edinburgh Neural Machine Translation Systems for WMT 16
- [Long Short-Term Memory](./long-short-term-memory.md)
- [Effective Approaches to Attention-based Neural Machine Translation](./effective-approaches-to-attention-based-neural-machine-translation.md)
- [Delving Deep into Rectifiers - Surpassing Human-Level Performance on ImageNet Classification](./delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification.md)
- Vocabulary Selection Strategies for Neural Machine Translation
- [Dropout - a simple way to prevent neural networks from overfitting](./dropout-a-simple-way-to-prevent-neural-networks-from-overfitting.md)
- [Neural Machine Translation of Rare Words with Subword Units](./neural-machine-translation-of-rare-words-with-subword-units.md)
- Cutting-off Redundant Repeating Generations for Neural Abstractive Summarization
- [Understanding the difficulty of training deep feedforward neural networks](./understanding-the-difficulty-of-training-deep-feedforward-neural-networks.md)
- [A Neural Attention Model for Abstractive Sentence Summarization](./a-neural-attention-model-for-abstractive-sentence-summarization.md)
- Vocabulary Manipulation for Neural Machine Translation
- Phoneme recognition using time-delay neural networks
- [Torch7 - A Matlab-like Environment for Machine Learning](./torch7-a-matlab-like-environment-for-machine-learning.md)
- Key-Value Memory Networks for Directly Reading Documents
- Finding Structure in Time
- Findings of the 2016 Conference on Machine Translation
- Japanese and Korean voice search
- A Simple, Fast, and Effective Reparameterization of IBM Model 2
- [ROUGE - A Package for Automatic Evaluation of Summaries](./rouge-a-package-for-automatic-evaluation-of-summaries.md)
- DUC in context
- The handbook of brain theory and neural networks
- Linguistic Data Consortium
- Convolutional networks for images, speech, and time series
