---
title: A Corpus for Reasoning about Natural Language Grounded in Photographs
authors:
- Alane Suhr
- Stephanie Zhou
- Iris Zhang
- Huajun Bai
- Yoav Artzi
fieldsOfStudy:
- Computer Science
meta_key: a-corpus-for-reasoning-about-natural-language-grounded-in-photographs
numCitedBy: 211
pdf_relpath: null
ref_count: 78
status: todo
tags:
- gen-from-ref
- paper
venue: ACL
year: 2019
---

# A Corpus for Reasoning about Natural Language Grounded in Photographs

## References

- A Corpus of Natural Language for Visual Reasoning
- Visual Entailment - A Novel Task for Fine-Grained Image Understanding
- Object Ordering with Bidirectional Matchings for Visual Reasoning
- [CLEVR - A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning](./clevr-a-diagnostic-dataset-for-compositional-language-and-elementary-visual-reasoning.md)
- TOUCHDOWN - Natural Language Navigation and Spatial Reasoning in Visual Street Environments
- [FigureQA - An Annotated Figure Dataset for Visual Reasoning](./figureqa-an-annotated-figure-dataset-for-visual-reasoning.md)
- “Caption” as a Coherence Relation - Evidence and Implications
- Bringing Semantics into Focus Using Visual Abstraction
- A Joint Model of Language and Perception for Grounded Attribute Learning
- Towards a Dataset for Human Computer Communication via Grounded Language Acquisition
- [VQA - Visual Question Answering](./vqa-visual-question-answering.md)
- Learning to interpret natural language navigation instructions from observations
- Using Syntax to Ground Referring Expressions in Natural Images
- [Visual Dialog](./visual-dialog.md)
- ShapeWorld - A new test methodology for multimodal language understanding
- Binary Image Selection (BISON) - Interpretable Evaluation of Visual Grounding
- ReferItGame - Referring to Objects in Photographs of Natural Scenes
- Cascaded Mutual Modulation for Visual Reasoning
- [Yin and Yang - Balancing and Answering Binary Visual Questions](./yin-and-yang-balancing-and-answering-binary-visual-questions.md)
- [From Recognition to Cognition - Visual Commonsense Reasoning](./from-recognition-to-cognition-visual-commonsense-reasoning.md)
- A Survey of Current Datasets for Vision and Language Research
- Weakly Supervised Semantic Parsing with Abstract Examples
- Learning Distributions over Logical Forms for Referring Expression Generation
- [Generation and Comprehension of Unambiguous Object Descriptions](./generation-and-comprehension-of-unambiguous-object-descriptions.md)
- GQA - a new dataset for compositional question answering over real-world images
- [Transparency by Design - Closing the Gap Between Performance and Interpretability in Visual Reasoning](./transparency-by-design-closing-the-gap-between-performance-and-interpretability-in-visual-reasoning.md)
- A dataset and architecture for visual reasoning with a working memory
- [Vision-and-Language Navigation - Interpreting Visually-Grounded Navigation Instructions in Real Environments](./vision-and-language-navigation-interpreting-visually-grounded-navigation-instructions-in-real-environments.md)
- [Neural-Symbolic VQA - Disentangling Reasoning from Vision and Language Understanding](./neural-symbolic-vqa-disentangling-reasoning-from-vision-and-language-understanding.md)
- Learning to Disambiguate by Asking Discriminative Questions
- [Neural Module Networks](./neural-module-networks.md)
- [Making the V in VQA Matter - Elevating the Role of Image Understanding in Visual Question Answering](./making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering.md)
- [Learning to Compose Neural Networks for Question Answering](./learning-to-compose-neural-networks-for-question-answering.md)
- Talk the Walk - Navigating New York City through Grounded Dialogue
- Natural Reference to Objects in a Visual Domain
- Bootstrap, Review, Decode - Using Out-of-Domain Textual Data to Improve Image Captioning
- TallyQA - Answering Complex Counting Questions
- [Don't Just Assume; Look and Answer - Overcoming Priors for Visual Question Answering](./don-t-just-assume-look-and-answer-overcoming-priors-for-visual-question-answering.md)
- [A simple neural network module for relational reasoning](./a-simple-neural-network-module-for-relational-reasoning.md)
- Structured Attentions for Visual Question Answering
- [WordNet - A Lexical Database for English](./wordnet-a-lexical-database-for-english.md)
- [Inferring and Executing Programs for Visual Reasoning](./inferring-and-executing-programs-for-visual-reasoning.md)
- [Compositional Attention Networks for Machine Reasoning](./compositional-attention-networks-for-machine-reasoning.md)
- [Microsoft COCO - Common Objects in Context](./microsoft-coco-common-objects-in-context.md)
- C-VQA - A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset
- [FiLM - Visual Reasoning with a General Conditioning Layer](./film-visual-reasoning-with-a-general-conditioning-layer.md)
- [An Analysis of Visual Question Answering Algorithms](./an-analysis-of-visual-question-answering-algorithms.md)
- [Learning to Reason - End-to-End Module Networks for Visual Question Answering](./learning-to-reason-end-to-end-module-networks-for-visual-question-answering.md)
- Walk the Talk - Connecting Language, Knowledge, and Action in Route Instructions
- [Explainable Neural Computation via Stack Neural Module Networks](./explainable-neural-computation-via-stack-neural-module-networks.md)
- TVQA - Localized, Compositional Video Question Answering
- [GloVe - Global Vectors for Word Representation](./glove-global-vectors-for-word-representation.md)
- Working Memory Networks - Augmenting Memory Networks with a Relational Reasoning Module
- [Efficient Estimation of Word Representations in Vector Space](./efficient-estimation-of-word-representations-in-vector-space.md)
- [BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding](./bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding.md)
- Mapping Instructions to Actions in 3D Environments with Visual Goal Prediction
- Learning Visual Question Answering by Bootstrapping Hard Attention
- Scalable multi-label annotation
- Finding Structure in Time
- Effectively Crowdsourcing Radiology Report Annotations
- [ImageNet Large Scale Visual Recognition Challenge](./imagenet-large-scale-visual-recognition-challenge.md)
- DDRprog - A CLEVR Differentiable Dynamic Reasoning Programmer
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](./very-deep-convolutional-networks-for-large-scale-image-recognition.md)
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- [Microsoft COCO Captions - Data Collection and Evaluation Server](./microsoft-coco-captions-data-collection-and-evaluation-server.md)
- [Adam - A Method for Stochastic Optimization](./adam-a-method-for-stochastic-optimization.md)
- [Long Short-Term Memory](./long-short-term-memory.md)
- [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](./inception-v4-inception-resnet-and-the-impact-of-residual-connections-on-learning.md)
- Mapping Navigation Instructions to Continuous Control Actions with Position-Visitation Prediction
- The measurement of observer agreement for categorical data.
- [Mask R-CNN](./mask-r-cnn.md)
