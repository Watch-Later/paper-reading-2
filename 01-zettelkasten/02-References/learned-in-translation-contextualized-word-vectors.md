---
title: Learned in Translation - Contextualized Word Vectors
authors:
- Bryan McCann
- James Bradbury
- Caiming Xiong
- R. Socher
fieldsOfStudy:
- Computer Science
meta_key: learned-in-translation-contextualized-word-vectors
numCitedBy: 710
pdf_relpath: null
ref_count: 74
status: todo
tags:
- gen-from-ref
- paper
venue: NIPS
year: 2017
---

# Learned in Translation - Contextualized Word Vectors

## References

- [Towards Universal Paraphrastic Sentence Embeddings](./towards-universal-paraphrastic-sentence-embeddings.md)
- [Supervised Learning of Universal Sentence Representations from Natural Language Inference Data](./supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data.md)
- [Skip-Thought Vectors](./skip-thought-vectors.md)
- Neural Semantic Encoders
- [Ask Me Anything - Dynamic Memory Networks for Natural Language Processing](./ask-me-anything-dynamic-memory-networks-for-natural-language-processing.md)
- [Sequence to Sequence Learning with Neural Networks](./sequence-to-sequence-learning-with-neural-networks.md)
- [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](./recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank.md)
- [GloVe - Global Vectors for Word Representation](./glove-global-vectors-for-word-representation.md)
- [Learning Word Vectors for Sentiment Analysis](./learning-word-vectors-for-sentiment-analysis.md)
- Encoding Syntactic Knowledge in Neural Networks for Sentiment Classification
- [Unsupervised Pretraining for Sequence to Sequence Learning](./unsupervised-pretraining-for-sequence-to-sequence-learning.md)
- The representational geometry of word meanings acquired by neural machine translation models
- Dependency Sensitive Convolutional Neural Networks for Modeling Sentences and Documents
- [Effective Approaches to Attention-based Neural Machine Translation](./effective-approaches-to-attention-based-neural-machine-translation.md)
- [Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond](./abstractive-text-summarization-using-sequence-to-sequence-rnns-and-beyond.md)
- Language to Logical Form with Neural Attention
- [Natural Language Processing (Almost) from Scratch](./natural-language-processing-almost-from-scratch.md)
- [Learning to Generate Reviews and Discovering Sentiment](./learning-to-generate-reviews-and-discovering-sentiment.md)
- Supervised and Semi-Supervised Text Categorization using LSTM for Region Embeddings
- Reading and Thinking - Re-read LSTM Unit for Textual Entailment Recognition
- [A large annotated corpus for learning natural language inference](./a-large-annotated-corpus-for-learning-natural-language-inference.md)
- Semi-supervised Sequence Learning
- [Neural Machine Translation by Jointly Learning to Align and Translate](./neural-machine-translation-by-jointly-learning-to-align-and-translate.md)
- Text Classification Improved by Integrating Bidirectional LSTM with Two-dimensional Max Pooling
- TopicRNN - A Recurrent Neural Network with Long-Range Semantic Dependency
- [Efficient Estimation of Word Representations in Vector Space](./efficient-estimation-of-word-representations-in-vector-space.md)
- [Framewise phoneme classification with bidirectional LSTM and other neural network architectures](./framewise-phoneme-classification-with-bidirectional-lstm-and-other-neural-network-architectures.md)
- [Learning Distributed Representations of Sentences from Unlabelled Data](./learning-distributed-representations-of-sentences-from-unlabelled-data.md)
- Question Answering through Transfer Learning from Large Fine-grained Supervision Data
- [A Decomposable Attention Model for Natural Language Inference](./a-decomposable-attention-model-for-natural-language-inference.md)
- Grounded Compositional Semantics for Finding and Describing Images with Sentences
- [Machine Comprehension Using Match-LSTM and Answer Pointer](./machine-comprehension-using-match-lstm-and-answer-pointer.md)
- A Neural Architecture Mimicking Humans End-to-End for Natural Language Inference
- SemEval-2014 Task 10 - Multilingual Semantic Textual Similarity
- [A Joint Many-Task Model - Growing a Neural Network for Multiple NLP Tasks](./a-joint-many-task-model-growing-a-neural-network-for-multiple-nlp-tasks.md)
- The IWSLT 2015 Evaluation Campaign
- Discriminative Neural Sentence Modeling by Tree-Based Convolution
- [Adversarial Training Methods for Semi-Supervised Text Classification](./adversarial-training-methods-for-semi-supervised-text-classification.md)
- Neural Tree Indexers for Text Understanding
- [SQuAD - 100,000+ Questions for Machine Comprehension of Text](./squad-100-000-questions-for-machine-comprehension-of-text.md)
- Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference
- [Bidirectional Attention Flow for Machine Comprehension](./bidirectional-attention-flow-for-machine-comprehension.md)
- [Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding](./multimodal-compact-bilinear-pooling-for-visual-question-answering-and-visual-grounding.md)
- [Knowing When to Look - Adaptive Attention via a Visual Sentinel for Image Captioning](./knowing-when-to-look-adaptive-attention-via-a-visual-sentinel-for-image-captioning.md)
- End-to-End Multi-View Networks for Text Classification
- [Dynamic Memory Networks for Visual and Textual Question Answering](./dynamic-memory-networks-for-visual-and-textual-question-answering.md)
- Recursive Neural Networks for Learning Logical Semantics
- From symbolic to sub-symbolic information in question classification
- [Moses - Open Source Toolkit for Statistical Machine Translation](./moses-open-source-toolkit-for-statistical-machine-translation.md)
- Learning question classifiers - the role of semantic information
- [Dynamic Coattention Networks For Question Answering](./dynamic-coattention-networks-for-question-answering.md)
- A Shared Task on Multimodal Machine Translation and Crosslingual Image Description
- [Gated Self-Matching Networks for Reading Comprehension and Question Answering](./gated-self-matching-networks-for-reading-comprehension-and-question-answering.md)
- Question Classification by Weighted Combination of Lexical, Syntactic and Semantic Features
- [OpenNMT - Open-Source Toolkit for Neural Machine Translation](./opennmt-open-source-toolkit-for-neural-machine-translation.md)
- [Batch Normalization - Accelerating Deep Network Training by Reducing Internal Covariate Shift](./batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.md)
- Improving Question Classification by Feature Extraction and Selection
- [Deep Residual Learning for Image Recognition](./deep-residual-learning-for-image-recognition.md)
- High Accuracy Rule-based Question Classification using Question Syntax and Semantics
- Heterogeneous Transfer Learning for Image Classification
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](./very-deep-convolutional-networks-for-large-scale-image-recognition.md)
- [ImageNet classification with deep convolutional neural networks](./imagenet-classification-with-deep-convolutional-neural-networks.md)
- [Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation](./rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.md)
- [ImageNet - A large-scale hierarchical image database](./imagenet-a-large-scale-hierarchical-image-database.md)
- [Maxout Networks](./maxout-networks.md)
- Deep Learning with Dynamic Computation Graphs
- The TREC-8 Question Answering Track Evaluation
- Adapting Visual Category Models to New Domains
- [Rectified Linear Units Improve Restricted Boltzmann Machines](./rectified-linear-units-improve-restricted-boltzmann-machines.md)
- Hedged Deep Tracking
- Open Source Toolkit for Statistical Machine Translation - Factored Translation Models and Lattice Decoding
- End-to-End Reading Comprehension with Dynamic Answer Chunk Ranking
