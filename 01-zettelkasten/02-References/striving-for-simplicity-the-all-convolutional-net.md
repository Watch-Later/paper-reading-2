---
title: Striving for Simplicity - The All Convolutional Net
authors:
- Jost Tobias Springenberg
- A. Dosovitskiy
- T. Brox
- Martin A. Riedmiller
fieldsOfStudy:
- Computer Science
meta_key: striving-for-simplicity-the-all-convolutional-net
numCitedBy: 3272
pdf_relpath: null
ref_count: 31
status: todo
tags:
- gen-from-ref
- paper
venue: ICLR
year: 2015
---

# Striving for Simplicity - The All Convolutional Net

## References

- [Very Deep Convolutional Networks for Large-Scale Image Recognition](./very-deep-convolutional-networks-for-large-scale-image-recognition.md)
- [ImageNet classification with deep convolutional neural networks](./imagenet-classification-with-deep-convolutional-neural-networks.md)
- [Network In Network](./network-in-network.md)
- [Deeply-Supervised Nets](./deeply-supervised-nets.md)
- [Going deeper with convolutions](./going-deeper-with-convolutions.md)
- Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks
- Fractional Max-Pooling
- [Visualizing and Understanding Convolutional Networks](./visualizing-and-understanding-convolutional-networks.md)
- High-Performance Neural Networks for Visual Object Classification
- [Learning Multiple Layers of Features from Tiny Images](./learning-multiple-layers-of-features-from-tiny-images.md)
- Deep Networks with Internal Selective Attention through Feedback Connections
- [Caffe - Convolutional Architecture for Fast Feature Embedding](./caffe-convolutional-architecture-for-fast-feature-embedding.md)
- Stochastic Pooling for Regularization of Deep Convolutional Neural Networks
- [Deep Inside Convolutional Networks - Visualising Image Classification Models and Saliency Maps](./deep-inside-convolutional-networks-visualising-image-classification-models-and-saliency-maps.md)
- Improving Deep Neural Networks with Probabilistic Maxout Units
- Beyond spatial pyramids - Receptive field learning for pooled image features
- Discriminative Transfer Learning with Tree-based Priors
- What is the best multi-stage architecture for object recognition?
- [Dropout - a simple way to prevent neural networks from overfitting](./dropout-a-simple-way-to-prevent-neural-networks-from-overfitting.md)
- [Gradient-based learning applied to document recognition](./gradient-based-learning-applied-to-document-recognition.md)
- [Regularization of Neural Networks using DropConnect](./regularization-of-neural-networks-using-dropconnect.md)
- [Improving neural networks by preventing co-adaptation of feature detectors](./improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors.md)
- [Maxout Networks](./maxout-networks.md)
- [ImageNet - A large-scale hierarchical image database](./imagenet-a-large-scale-hierarchical-image-database.md)
- Signal recovery from Pooling Representations
- [Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks](./under-review-as-a-conference-paper-at-iclr-2017-delving-into-transferable-adversarial-ex-amples-and-black-box-attacks.md)
- Hierarchical Neural Networks for Image Interpretation
- Compete to Compute
